{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['savefig.dpi'] = 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Natural Language Processing\n",
    "\n",
    "Natural language processing (NLP) is the field devoted to methods and algorithms for processing human (natural) languages for computers. NLP is a vast discipline that is actively being researched. For this notebook, we will be concerned with NLP tools and techniques we can use for machine learning applications. Some examples of machine learning applications using NLP include sentiment analysis, topic modeling, and language translation. In NLP, the following terms have specific meanings:\n",
    "\n",
    "* **Corpus**: The body/collection of text being investigated.\n",
    "* **Document**: The unit of analysis, what is considered a single observation.\n",
    "\n",
    "Examples of corpora include a collection of reviews and tweets, the text of the _Iliad_, and Wikipedia articles. Documents can be whatever you decided, it is what your model will consider an observation. For the example when the corpus is a collection of reviews or tweets, it is logical to make the document a single review or tweet. For the example of the text of the _Iliad_, we can set the document size to a sentence or a paragraph. The choice of document size will be influenced by the size of our corpus. If it is large, it may make sense to call each paragraph a document. As is usually the case, some design choices that need to be made.\n",
    "\n",
    "For this notebook, we will build a classifier to discern homonyms, words that are spelled the same but that have different meanings. The exact use case we will explore is to discern if the word \"python\" refers to the programming language or the animal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP with spaCy\n",
    "\n",
    "spaCy is a Python package that bills itself as \"industrial-strength\" natural language processing. We will use the tools spaCy provides in conjunction with `scikit-learn`. Let's explore some of spaCy's capabilities; we will introduce more functionality when needed. More about spaCy can be found [here](https://spacy.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's try out spacy.\n",
      "We can easily divide our text into sentences!\n",
      "I've run out of ideas.\n",
      "Let\n",
      "We\n",
      "'s\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# load text processing pipeline\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "sentences = []\n",
    "# nlp accepts a string\n",
    "doc = nlp(\"Let's try out spacy. We can easily divide our text into sentences! I've run out of ideas.\")\n",
    "\n",
    "# iterate through each sentence\n",
    "for sent in doc.sents:\n",
    "    print(sent)\n",
    "    #sentences += [doc.sents.]\n",
    "\n",
    "# index words\n",
    "print(doc[0])\n",
    "print(doc[6])\n",
    "print (doc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another nice feature from spaCy is part-of-speech tagging, the process of identifying whether a word is a noun, adjective, adverb, etc. A processed word has the attribute `pos_` and `tag_`; the former identifies the simple part of speech (e.g., noun) wile the the latter identifies the more detailed part of speech (e.g., proper noun). The meaning of the resulting abbreviations of the `tag_` are listed [here](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html) or can be revealed by running `spacy.explain` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the', 'DET', 'DT')\n",
      "('quick', 'ADJ', 'JJ')\n",
      "('brown', 'ADJ', 'JJ')\n",
      "('fox', 'NOUN', 'NN')\n",
      "('jumps', 'VERB', 'VBZ')\n",
      "('over', 'ADP', 'IN')\n",
      "('the', 'DET', 'DT')\n",
      "('lazy', 'ADJ', 'JJ')\n",
      "('dog', 'NOUN', 'NN')\n",
      "{'JJ', 'VBZ', 'IN', 'NN', 'DT'}\n",
      "{'DET', 'VERB', 'ADJ', 'ADP', 'NOUN'}\n"
     ]
    }
   ],
   "source": [
    "doc = nlp ('the quick brown fox jumps over the lazy dog')\n",
    "tags = set()\n",
    "pos = set()\n",
    "\n",
    "for word in doc:\n",
    "    tags.add (word.tag_)\n",
    "    pos.add (word.pos_)\n",
    "    print ((word.text, word.pos_, word.tag_))\n",
    "    \n",
    "print (tags)\n",
    "print (pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The', 'DET', 'DT')\n",
      "('quick', 'ADJ', 'JJ')\n",
      "('brown', 'ADJ', 'JJ')\n",
      "('fox', 'NOUN', 'NN')\n",
      "('jumped', 'VERB', 'VBD')\n",
      "('over', 'ADP', 'IN')\n",
      "('the', 'DET', 'DT')\n",
      "('lazy', 'ADJ', 'JJ')\n",
      "('dog', 'NOUN', 'NN')\n",
      "('.', 'PUNCT', '.')\n",
      "('Mr.', 'PROPN', 'NNP')\n",
      "('Peanut', 'PROPN', 'NNP')\n",
      "('wears', 'VERB', 'VBZ')\n",
      "('a', 'DET', 'DT')\n",
      "('top', 'ADJ', 'JJ')\n",
      "('hat', 'NOUN', 'NN')\n",
      "('.', 'PUNCT', '.')\n",
      "\n",
      "JJ adjective\n",
      "VBZ verb, 3rd person singular present\n",
      "VBD verb, past tense\n",
      "NNP noun, proper singular\n",
      "IN conjunction, subordinating or preposition\n",
      "NN noun, singular or mass\n",
      "DT determiner\n",
      ". punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"The quick brown fox jumped over the lazy dog. Mr. Peanut wears a top hat.\")\n",
    "tags = set()\n",
    "\n",
    "# reveal part of speech\n",
    "for word in doc:\n",
    "    tags.add(word.tag_)\n",
    "    print((word.text, word.pos_, word.tag_))\n",
    "\n",
    "# revealing meaning of tags\n",
    "print()\n",
    "for tag in tags:\n",
    "    print(tag, spacy.explain(tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining a corpus\n",
    "\n",
    "Before we can move on with our analysis, we need to obtain a corpus. For our intended classifier, we need documents pertaining to python the animal and Python the programming language. Let's use Wikipedia articles to form our corpus. Luckily, there's a Python package called `wikipedia` that makes it easy to fetch articles. We will create documents based on the sentences in the articles. The function allows us to pass multiples pages in constructing the documents, allowing us to prevent one class of documents from dominating the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\kagum\\anaconda3\\lib\\site-packages (from wikipedia) (4.9.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\kagum\\anaconda3\\lib\\site-packages (from wikipedia) (2.25.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kagum\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\kagum\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kagum\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\kagum\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (4.0.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\kagum\\anaconda3\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.2.1)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py): started\n",
      "  Building wheel for wikipedia (setup.py): finished with status 'done'\n",
      "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11686 sha256=ec5efb918a4333663efae2f295234bf99dc36825b0ab09ede904c4ece6956c5d\n",
      "  Stored in directory: c:\\users\\kagum\\appdata\\local\\pip\\cache\\wheels\\07\\93\\05\\72c05349177dca2e0ba31a33ba4f7907606f7ddef303517c6a\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `p.content` not found.\n"
     ]
    }
   ],
   "source": [
    "p.content?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "\n",
    "def pages_to_sentences(*pages):\n",
    "    \"\"\"Return a list of sentences in Wikipedia articles.\"\"\"\n",
    "    sentences = []\n",
    "    \n",
    "    for page in pages:\n",
    "        p = wikipedia.page(page)\n",
    "        doc = nlp(p.content)\n",
    "        sentences += [sent.text for sent in doc.sents]\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "# animal_sents = pages_to_sentences(\"Reticulated python\", \"Ball Python\")\n",
    "# language_sents = pages_to_sentences(\"Python (programming language)\")\n",
    "# documents = animal_sents + language_sents\n",
    "\n",
    "# print(language_sents[:5])\n",
    "# print()\n",
    "# print(animal_sents[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**\n",
    "* Given the example documents, what patterns should our word usage classifier learn?\n",
    "* We chose to create documents from sentences. What are other options? What are some pros and cons?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words model\n",
    "\n",
    "Machine learning models needs to ingest data in a structured form, a matrix where the rows represents observations and the columns are features/attributes. When working with text data, we need a method to convert this unstructured data into a form that the machine learning model can work with. Let's consider our motivating example to create a classifier to discern the usage of \"python\" in a document. We understand that documents referring to the programming language will use words such as \"integer\", \"byte\", and \"error\" at higher frequency than documents that refer to python the animal. The reverse is true for words such as \"bite\", \"snake\", and \"pet\". One technique to _transform_ text data into a matrix is to count the number of appearances of each word in each document. This technique is called the **bag of words** model. The model gets its name because each document is viewed as a bag holding all the words, disregarding word order, context, and grammar. After applying the bag of words model to a corpus, the resulting matrix will exhibit patterns that a machine learning model can exploit. See the example below for the result of applying the bag of words model to a corpus of two documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document 0: \"The python is a large snake, although the snake is not venomous.\" <br>\n",
    "Document 1: \"Python is an interpreted programming language for general purpose programming.\" <br>\n",
    "<br>\n",
    "\n",
    "| although | an | for | general | interpreted | is | language | large | not | programming | purpose | python | snake | the | venomous |\n",
    "|:--------:|----|-----|---------|-------------|----|----------|-------|-----|-------------|---------|--------|-------|-----|----------|\n",
    "|     1    | 0  | 0   | 0       | 0           | 2  | 0        | 1     | 1   | 0           | 0       | 1      | 2     | 2   | 1        |\n",
    "|     0    | 1  | 1   | 1       | 1           | 1  | 1        | 0     | 0   | 2           | 1       | 1      | 0     | 0   | 0        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `CountVectorizer` transformer\n",
    "\n",
    "The bag of words model is found in `scikit-learn` with the `CountVectorizer` transformer. Note, `scikit-learn` uses the word `Vectorizer` to refer to transformers that convert a data structure (like a dictionary) into a NumPy array. Since it is a transformer, we need to first fit the object and _then_ call `transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The reticulated python (Malayopython reticulatus) is a python species native to South and Southeast Asia.',\n",
       " \"It is the world's longest snake, and listed as least concern on the IUCN Red List because of its wide distribution.\",\n",
       " 'In several countries in its range, it is hunted for its skin, for use in traditional medicine, and for sale as a pet.',\n",
       " 'It is an excellent swimmer, has been reported far out at sea, and has colonized many small islands within its range.',\n",
       " '\\n',\n",
       " 'It is among the three heaviest snakes.',\n",
       " 'Like all pythons, it is a non-venomous constrictor.',\n",
       " 'Adult humans have been killed (and in at least two reported cases, eaten) by reticulated pythons.',\n",
       " '\\n\\n\\n=',\n",
       " '=',\n",
       " 'Taxonomy ==\\n',\n",
       " 'The reticulated python was first described in 1801 by German naturalist Johann Gottlob Theaenus Schneider, who described two zoological specimens held by the Göttingen Museum in 1801 that differed slightly in colour and pattern as separate species—Boa reticulata and Boa rhombeata.  ',\n",
       " 'The specific name, reticulatus, is Latin meaning \"net-like\", or reticulated, and is a reference to the complex color pattern.',\n",
       " 'The generic name Python was proposed by French naturalist François Marie Daudin in 1803.',\n",
       " 'American zoologist Arnold G. Kluge performed a cladistics analysis on morphological characters and recovered the reticulated python lineage as sister to the genus Python, hence not requiring a new generic name in 1993.In a 2004 genetics study using cytochrome b DNA, Robin Lawson and colleagues discovered the reticulated python as sister to Australo-Papuan pythons, rather than Python molurus and relatives.',\n",
       " 'Raymond Hoser erected the genus Broghammerus for the reticulated python in 2004, naming it after German snake expert Stefan Broghammer, on the basis of dorsal patterns distinct from those of the genus Python, and a dark mid-dorsal line from the rear to the front of the head, and red or orange (rather than brown) iris colour.',\n",
       " \"In 2008, Lesley Rawlings and colleagues reanalysed Kluge's morphological data and combined it with genetic material, and found the reticulated clade to be an offshoot of the Australo-Papuan lineage as well.\",\n",
       " 'They adopted and redefined the genus name Broghammerus.',\n",
       " 'However, this and numerous other names by the same author were criticized by several authors, who proposed ignoring them for the purposes of nomenclature.',\n",
       " 'R. Graham Reynolds and colleagues subsequently described the genus Malayopython for this species and its sister species, the Timor python, calling the Timor python M. timoriensis.',\n",
       " 'Hoser has since said that the Malayopython name is a junior synonym of Broghammerus, thus it should not be recognized by the International Code of Zoological Nomenclature.',\n",
       " 'Neither of these proposed reclassifications has been recognized by the ITIS, but Malayopython has been recognized by a number of subsequent authors and the Reptile Database.',\n",
       " '\\n\\n\\n===',\n",
       " 'Subspecies ===\\n',\n",
       " 'Three subspecies have been proposed:\\n\\nM. r. reticulatus (Schneider, 1801) - Asiatic reticulated python\\nM. r. jampeanus Auliya et al., 2002 – Kayaudi reticulated python or Tanahjampean reticulated python, about half the length, or according to Auliya et al.',\n",
       " '(2002), not reaching much more than 2 m (6 ft 7 in) in length.',\n",
       " 'Found on Tanahjampea in the Selayar Archipelago south of Sulawesi.',\n",
       " 'Closely related to M. r. reticulatus of the Lesser Sundas.',\n",
       " '\\nM. r. saputrai Auliya et al., 2002 – Selayer reticulated python, occurs on Selayar Island in the Selayar Archipelago and also in adjacent Sulawesi.',\n",
       " 'This subspecies represents a sister lineage to all other populations of reticulated pythons tested.',\n",
       " 'According to Auliya et al.',\n",
       " '(2002) it does not exceed 4 m (13 ft 1 in) in length.',\n",
       " 'The latter two are dwarf subspecies.',\n",
       " 'Apparently, the population of the Sangihe Islands north of Sulawesi represents another such subspecies, which is basal to the P. r. reticulatus plus P. r. jampeanus clade, but it is not yet formally described.',\n",
       " 'The proposed subspecies M. r. \"dalegibbonsi\", M. r. \"euanedwardsi\", M. r. \"haydnmacphiei\", M. r. \"neilsonnemani\", M. r. \"patrickcouperi\", and M. r. \"stuartbigmorei\" have not found general acceptance.',\n",
       " '\\n\\n\\n==',\n",
       " 'Description ==\\n\\n',\n",
       " 'The reticulated python has smooth dorsal scales that are arranged in 69–79 rows at midbody.',\n",
       " 'Deep pits occur  on four anterior upper labials, on two or three anterior lower labials, and on five or six posterior lower labials.',\n",
       " 'The reticulated python is the largest snake native to Asia.',\n",
       " 'More than a thousand wild reticulated pythons in southern Sumatra were studied, and estimated to have a length range of 1.5 to 6.5 m (4 ft 11 in to 21 ft 4 in), and a weight range of 1 to 75 kg (2 lb 3 oz to 165 lb 6 oz).',\n",
       " 'Reticulated pythons with lengths more than 6 m (19 ft 8 in) are rare, though according to the Guinness Book of World Records, it is the only extant snake to regularly exceed that length.',\n",
       " 'One of the largest scientifically measured specimens, from Balikpapan, East Kalimantan, Indonesia, was measured under anesthesia at 6.95 m (22 ft 10 in), and weighed 59 kg (130 lb 1 oz) after not having eaten for nearly 3 months.',\n",
       " 'The specimen once widely accepted as the largest-ever \"accurately\" measured snake, that being Colossus, a specimen kept at the Highland Park Zoo (now the Pittsburgh Zoo and PPG Aquarium) in Pittsburgh, Pennsylvania, during the 1950s and early 1960s, with a peak reported length of 8.7 metres (28 ft 7 in) from a measurement in November 1956, was later shown to have been substantially shorter than previously reported.',\n",
       " 'When Colossus died on 14 April 1963, its body was deposited in the Carnegie Museum of Natural History.',\n",
       " 'At that time, its skeleton was measured and found to be 20 ft 10 in (6.35 m) in total length, and the length of its fresh hide was measured as 23 ft 11 in (7.29 m) – both measurements being significantly shorter than what had been previously estimated in 1956.',\n",
       " 'The hide tends to stretch from the skinning process, thus may be longer than the snake from which it came – e.g., by roughly 20–40% or more.',\n",
       " 'The previous reports had been constructed by combining partial measurements with estimations to compensate for \"kinks\", since completely straightening an extremely large live python is virtually impossible.',\n",
       " 'Because of these issues, a 2012 journal article concluded, \"Colossus was neither the longest snake nor the heaviest snake ever maintained in captivity.',\n",
       " '\" Too large to be preserved with formaldehyde and then stored in alcohol, the specimen was instead prepared as a disarticulated skeleton.',\n",
       " \"The hide was sent to a laboratory to be tanned, but it was either lost or destroyed, and now only the skull and selected vertebrae and ribs remain in the museum's collection.\",\n",
       " 'Considerable confusion exists in the literature over whether Colossus was male or female (females tend to be larger).',\n",
       " '\\n',\n",
       " 'Numerous reports have been made of larger snakes, but since none of these was measured by a scientist nor any of the specimens deposited at a museum, they must be regarded as unproven and possibly erroneous.',\n",
       " 'In spite of what has been, for many years, a standing offer of a large financial reward (initially $1,000, later raised to $5,000, then $15,000 in 1978 and $50,000 in 1980) for a live, healthy snake over 30 ft (9.14 m) long by the New York Zoological Society (later renamed as the Wildlife Conservation Society), no attempt to claim this reward has ever been made.',\n",
       " 'The colour pattern is a complex geometric pattern that incorporates different colours.',\n",
       " 'The back typically has a series of irregular diamond shapes flanked by smaller markings with light centers.',\n",
       " \"In this species' wide geographic range, much variation of size, colour, and markings commonly occurs.\",\n",
       " '\\n',\n",
       " 'In zoo exhibits, the colour pattern may seem garish, but in a shadowy jungle environment amid fallen leaves and debris, it allows them to virtually disappear.',\n",
       " 'Called disruptive colouration, it protects them from predators and helps them to catch their prey.',\n",
       " 'The huge size and attractive pattern of this snake has made it a favorite zoo exhibit, with several individuals claimed to be above 20 ft (6.1 m) in length and more than one claimed to be the largest in captivity.',\n",
       " 'However, due to its huge size, immense strength, aggressive disposition, and the mobility of the skin relative to the body, it is very difficult to get exact length measurements of a living reticulated python, and weights are rarely indicative, as captive pythons are often obese.',\n",
       " 'Claims made by zoos and animal parks are sometimes exaggerated, such as the claimed 14.85 m (48 ft 9 in) snake in Indonesia which was subsequently proven to be about 6.5–7 m (21 ft 4 in–23 ft 0 in) long.',\n",
       " 'For this reason, scientists do not accept the validity of length measurements unless performed on a dead or anesthetized snake that is later preserved in a museum collection or stored for scientific research.',\n",
       " 'A reticulated python kept in Kansas City, Missouri, named \"Medusa\" is considered by the Guinness Book of World Records to be the longest living snake ever kept in captivity.',\n",
       " 'In 2011 it was reported to measure 7.67 m (25 ft 2 in) and weigh 158.8 kg (350 lb 2 oz).Dwarf forms of reticulated pythons also occur, from some islands  northwest of Australia, and these are being selectively bred in captivity to be much smaller, resulting in animals often referred to as \"super dwarfs\".',\n",
       " 'Adult super dwarf reticulated pythons are typically between 1.82 and 2.4 m (6 ft 0 in and 7 ft 10 in) in length.',\n",
       " '\\n\\n\\n==',\n",
       " 'Distribution and habitat ==',\n",
       " '\\n\\n',\n",
       " 'The reticulated python is found in South and Southeast Asia from the Nicobar Islands, India, Bangladesh, Myanmar, Thailand, Laos, Cambodia, Vietnam, Malaysia, and Singapore, east through Indonesia and the Indo-Australian Archipelago (Sumatra, the Mentawai Islands, the Natuna Islands, Borneo, Sulawesi, Java, Lombok, Sumbawa, Sumba, Flores, Timor, Maluku, Tanimbar Islands) and the Philippines (Basilan, Bohol, Cebu, Leyte, Luzon, Mindanao, Mindoro, Negros, Palawan, Panay, Polillo, Samar, Tawi-Tawi).',\n",
       " 'The original description does not include a type locality.',\n",
       " 'The type locality was restricted to \"Java\" by Brongersma (1972).Three subspecies have been proposed, but are not recognized in the Integrated Taxonomic Information System.',\n",
       " 'The color and size can vary a great deal among the subspecies described.',\n",
       " 'Geographical location is a good key to establishing the subspecies, as each one has a distinct geographical range.',\n",
       " '\\n',\n",
       " 'The reticulated python lives in rainforests, woodlands, and nearby grasslands.',\n",
       " 'It is also associated with rivers and is found in areas with nearby streams and lakes.',\n",
       " 'An excellent swimmer, it has even been reported far out at sea and has consequently colonized many small islands within its range.',\n",
       " 'During the early years of the 20th century, it is said to have been common even in busy parts of Bangkok, sometimes eating domestic animals.',\n",
       " '\\n\\n\\n=',\n",
       " '=',\n",
       " 'Behaviour and ecology ==\\n\\n\\n==',\n",
       " '= Diet ===\\n\\n',\n",
       " 'As with all pythons, the reticulated python is an ambush predator, usually waiting until prey wanders within strike range before seizing it in its coils and killing by constriction.',\n",
       " 'Its natural diet includes mammals and occasionally birds.',\n",
       " 'Small specimens up to 3–4 m (9 ft 10 in–13 ft 1 in) long eat mainly small mammals such as rats, other rodents, mouse-eared bats, and treeshrews,whereas larger individuals switch to prey such as small Indian civet and binturong, primates, pigs, and deer weighing more than 60 kg (132 lb 4 oz).',\n",
       " 'As a rule, the reticulated python seems able to swallow prey up to one-quarter its own length and up to its own weight.',\n",
       " 'Near human habitation, it is known to snatch stray chickens, cats, and dogs on occasion.',\n",
       " '\\n',\n",
       " 'Among the largest documented prey items are a half-starved sun bear of 23 kg (50 lb 11 oz) that was eaten by a 6.95 m (22 ft 10 in) specimen and took some 10 weeks to digest.',\n",
       " '\\n',\n",
       " 'At least one case is reported of a foraging python entering a forest hut and taking a child.',\n",
       " '\\n\\n\\n==',\n",
       " '=',\n",
       " 'Reproduction ===\\n',\n",
       " 'The reticulated python is oviparous.',\n",
       " 'Adult females lay between 15 and 80 eggs per clutch.',\n",
       " 'At an optimum incubation temperature of 31–32 °C (88–90 °F), the eggs take an average of 88 days to hatch.',\n",
       " 'Hatchlings are at least 61 cm (2 ft) in length.',\n",
       " '\\n\\n\\n=',\n",
       " '=',\n",
       " 'Danger to humans ==',\n",
       " '\\n\\n',\n",
       " 'The reticulated python is among the few snakes that prey on humans.',\n",
       " 'On April 9, 2015, the species was added to the Lacey Act list in the United States, prohibiting import and interstate transport due to its \"injurious\" history with humans.',\n",
       " 'Attacks on humans are not common, but this species has been responsible for several reported human fatalities, in both the wild and captivity.',\n",
       " 'Considering the known maximum prey size, a full-grown reticulated python can open its jaws wide enough to swallow a human, but the width of the shoulders of some adult Homo sapiens can pose a problem for even a snake with sufficient size.',\n",
       " 'Reports of human fatalities and human consumption (the latest examples of consumption of an adult human being well authenticated) include:\\n\\nIn early 20th-century Indonesia:',\n",
       " 'On Salibabu island, North Sulawesi, a 14-year-old boy was killed and supposedly eaten by a specimen 5.17 m (17 ft 0 in) in length.',\n",
       " 'Another incident involved a woman reputedly eaten by a \"large reticulated python\", but few details are known.\\n',\n",
       " 'In the early 1910s or in 1927, a jeweller went hunting with his friends and was apparently eaten by a 6 m (19 ft 8 in) python after he sought shelter from a rainstorm in or under a tree.',\n",
       " 'Supposedly, he was swallowed feet-first, perhaps the easiest way for a snake to actually swallow a human.\\n',\n",
       " 'In 1932, Frank Buck wrote about a teenaged boy who was eaten by a pet 25 ft (7.6 m) reticulated python in the Philippines.',\n",
       " \"According to Buck, the python escaped, and when it was found, a human child's shape was recognized inside the snake, and turned out to be the son of the snake's owner.\\n\",\n",
       " 'Among a small group of Aeta negritos in the Philippines, six deaths by pythons were said to have been documented within a period of 40 years, plus one who died later of an infected bite.\\n',\n",
       " 'In September 1995, a 29-year-old rubber tapper from the southern Malaysian state of Johor was reported to have been killed by a large reticulated python.',\n",
       " 'The victim had apparently been caught unaware and was squeezed to death.',\n",
       " \"The snake had coiled around the lifeless body with the victim's head gripped in its jaws when it was stumbled upon by the victim's brother.\",\n",
       " 'The python, reported as measuring 23 ft (7.0 m) long and weighing more than 300 lb, was killed soon after by the arriving police, who shot it four times.',\n",
       " '\\n',\n",
       " 'In October 2008, a 25-year-old woman appeared to have been killed by a 13-foot (4.0 m) pet reticulated python.',\n",
       " 'The apparent cause of death was asphyxiation.',\n",
       " 'The snake was later found in the bedroom in an agitated state.',\n",
       " '\\n',\n",
       " 'In January 2009, a 3-year-old boy was wrapped in the coils of a 18 ft (5.5 m) pet reticulated python, turning blue.',\n",
       " \"The boy's mother, who had been petsitting the python on behalf of a friend, rescued the toddler by gashing the python with a knife.\",\n",
       " 'The snake was later euthanized because of its wounds.',\n",
       " '\\n',\n",
       " \"In December 2013, a 59-year-old security guard was strangled to death while trying to capture a python near the Bali Hyatt, a luxury hotel on Indonesia's resort island.\",\n",
       " ' ',\n",
       " 'The incident happened around 3 am as the 4.5-m (15-ft) python was crossing a road near the hotel.',\n",
       " ' ',\n",
       " 'The victim had offered to help capture the snake, which had been spotted several times before near the hotel in the Sanur, Bali, area and escaped back into nearby bushes.',\n",
       " '\\n',\n",
       " 'In March 2017, the body of Akbar Salubiro, a 25-year-old farmer in Central Mamuju Regency, West Sulawesi, Indonesia, was found inside the stomach of a 7 m (23 ft 0 in) reticulated python.',\n",
       " 'He had been declared missing from his palm tree plantation, and the people searching for him found the python the next day with a large bulge in its stomach.',\n",
       " 'They killed the python and found the whole body of the missing farmer inside.',\n",
       " 'This was the first fully confirmed case of a person being eaten by a python.',\n",
       " \"The process of retrieving the body from the python's stomach was documented by pictures and videos taken by witnesses.\",\n",
       " '\\n',\n",
       " 'In June 2018, a 54-year-old Indonesian woman in Muna Island, Southeast Sulawesi, Indonesia, was killed and eaten by a 23-ft python.',\n",
       " 'The woman went missing one night while working in her garden, and the next day, a search party was organized after some of her belongings were found abandoned in the garden.',\n",
       " 'The python was found near the garden with a large bulge in its body.',\n",
       " \"The snake was killed and carried into town, where it was cut open, revealing the woman's body completely intact.\",\n",
       " 'A video of the snake being gutted was posted online.',\n",
       " '\\n',\n",
       " 'In June 2020, a 16-year-old Indonesian boy was attacked and killed by a 7 m (23 ft 0 in) long python in Bombana Regency, Southeast Sulawesi, Indonesia.',\n",
       " 'The incident took place near a waterfall at Mount Kahar in Rumbia sub-district.',\n",
       " 'The victim was separated from his four friends in the woods.',\n",
       " 'When he screamed, his friends came to help and found him encoiled by a large python.',\n",
       " 'Villagers came to help and managed to kill the snake using a parang machete.',\n",
       " 'However, the victim had already suffocated.',\n",
       " '\\n\\n\\n==',\n",
       " 'As a pet ==\\n\\nIncreased popularity of the reticulated python in the pet trade is due largely to increased efforts in captive breeding and selectively bred mutations such as the \"albino\" and \"tiger\" strains.',\n",
       " 'It can make a good captive, but keepers should have previous experience with large constrictors to ensure safety to both animal and keeper.',\n",
       " 'Although its interactivity and beauty draws much attention, some feel it is unpredictable.',\n",
       " 'It does not attack humans by nature, but will bite and possibly constrict if it feels threatened, or mistakes a hand for food.',\n",
       " 'While not venomous, large pythons can inflict serious injuries, sometimes requiring stitches.',\n",
       " '\\n\\n\\n=',\n",
       " '= See also ==',\n",
       " '\\n',\n",
       " 'List of largest snakes\\nBurmese python\\n\\n\\n==',\n",
       " 'References ==\\n\\n\\n==',\n",
       " 'Further reading ==\\n\\n\\n==',\n",
       " 'External links ==\\n',\n",
       " 'Reticulated python life history at Reticulatedpython.info .',\n",
       " 'Accessed 7 November 2009\\n',\n",
       " 'Python reticulatus at  ReptileExpert.org.',\n",
       " 'Accessed 22 August 2011.',\n",
       " '\\n',\n",
       " 'Reticulated python at Answers.com.',\n",
       " 'Accessed 12 September 2007.',\n",
       " '\\n',\n",
       " 'Study of man-eating snakes: Snakes are predators on, prey of, and competitors with primates Cornell Chronicle Online.',\n",
       " 'Accessed 22 December 2011.',\n",
       " '\\n',\n",
       " \"25 ft World's Longest Snake\\nPython swallows Indonesian man whole\",\n",
       " 'Fox News',\n",
       " 'The ball python (Python regius), also called the royal python, is a python species native to West and Central Africa, where it lives in grasslands, shrublands and open forests.',\n",
       " 'It is listed as Least Concern on the IUCN Red List because of its wide distribution.',\n",
       " 'It is threatened by hunting for its meat and for the international pet trade.',\n",
       " 'This nonvenomous constrictor is the smallest of the African pythons, growing to a maximum length of 182 cm (72 in).',\n",
       " 'The name \"ball python\" refers to its tendency to curl into a ball when stressed or frightened.',\n",
       " '\\n\\n\\n==',\n",
       " 'Taxonomy ==\\n',\n",
       " 'Boa regia was the scientific name proposed by George Shaw in 1802 for a pale variegated python from an indistinct place in Africa.',\n",
       " '\\n',\n",
       " 'The generic name Python was proposed by François Marie Daudin in 1803 for non-venomous flecked snakes.',\n",
       " 'Between 1830 and 1849, several generic names were proposed for the same zoological specimen described by Shaw, including Enygrus by Johann Georg Wagler, Cenchris and Hertulia by John Edward Gray.',\n",
       " 'Gray also described four specimens that were collected in Gambia and were preserved in spirits and fluid.',\n",
       " '\\n\\n\\n==',\n",
       " 'Description ==\\n\\n',\n",
       " 'The ball python is black or dark brown with light brown blotches on the back and sides.',\n",
       " 'Its white or cream belly is scattered with black markings.',\n",
       " 'It is a stocky snake with a relatively small head and smooth scales.',\n",
       " 'It reaches a maximum adult length of 182 cm (6.0 ft).',\n",
       " 'Males typically measure eight to ten subcaudal scales, and females typically measure two to four subcaudal scales.',\n",
       " 'Females reach an average snout-to-vent length of 116.2 cm (45.7 in), a 44.3 mm (1.74 in) long jaw, an 8.7 cm (3.4 in) long tail and a maximum weight of 1.635 kg (3.60 lb).',\n",
       " 'Males are smaller with an average snout-to-vent length of 111.3 cm (43.8 in), a 43.6 mm (1.72 in) long jaw, an 8.6 cm (3.4 in) long tail and a maximum weight of 1.561 kg (3.44 lb).',\n",
       " '\\n',\n",
       " 'Both sexes have pelvic spurs on both sides of the vent.',\n",
       " 'During copulation, males use these spurs for gripping females.',\n",
       " 'Males tend to have larger spurs, and sex is best determined by manual eversion of the male hemipenes or inserting a probe into the cloaca to check the presence of an inverted hemipenis.',\n",
       " '\\n\\n\\n==',\n",
       " 'Distribution and habitat ==\\n',\n",
       " 'The ball python is native to west Sub Saharan Africa from Senegal, Mali, Guinea-Bissau, Guinea, Sierra Leone, Liberia, Ivory Coast, Ghana, Benin, and Nigeria through Cameroon, Chad, and the Central African Republic to Sudan and Uganda.',\n",
       " '\\n',\n",
       " 'It prefers grasslands, savannas, and sparsely wooded areas.',\n",
       " '\\n\\n\\n==',\n",
       " 'Behavior and ecology =',\n",
       " '=\\n',\n",
       " 'This terrestrial species is known for its defense strategy that involves coiling into a tight ball when threatened, with its head and neck tucked away in the middle.',\n",
       " 'In this state, it can literally be rolled around.',\n",
       " 'Favored retreats include mammal burrows and other underground hiding places, where they also aestivate.',\n",
       " 'In captivity, they are considered good pets, with their relatively small size and placid nature making them easy to handle.',\n",
       " 'Males tend to display more semi-arboreal behaviors, whilst females tend towards terrestrial behaviors.',\n",
       " '\\n\\n\\n==',\n",
       " '= Diet ===\\n',\n",
       " 'The diet of the ball python in the wild consists mostly of small mammals such as rodents, shrews and birds.',\n",
       " 'Young ball pythons of less than 70 cm (28 in) prey foremost on small birds.',\n",
       " 'Ball pythons longer than 100 cm (39 in) prey foremost on small mammals.',\n",
       " 'Males prey more frequently on birds, and females more frequently on mammals.',\n",
       " 'Rodent prey include Gambian pouched rats, black rats, rufous-nosed rats, shaggy rats, and striped grass mice.',\n",
       " '\\n\\n\\n==',\n",
       " '=',\n",
       " 'Reproduction ===\\n\\nFemales are oviparous and lay three to 11 rather large, leathery eggs.',\n",
       " 'The eggs hatch after 55 to 60 days.',\n",
       " 'Young male pythons reach sexual maturity at 11–18 months, and females at 20–36 months.',\n",
       " 'Age is only one factor in determining sexual maturity and the ability to breed; weight is the second factor.',\n",
       " 'Males breed at 600 g (21 oz) or more, but in captivity are often not bred until they are 800 g (28 oz), although in captivity, some males have been known to begin breeding at 300–400 g (11–14 oz).',\n",
       " 'Females breed in the wild at weights as low as 800 g (28 oz) though 1,200 g (42 oz) or more in weight is most common; in captivity, breeders generally wait until they are no less than 1,500 g (53 oz).',\n",
       " 'Parental care of the eggs ends once they hatch, and the female leaves the offspring to fend for themselves.',\n",
       " '\\n\\n\\n=',\n",
       " '=',\n",
       " 'In captivity ==\\n\\nPython breeders have developed many morphs with altered colors and patterns.',\n",
       " '\\n',\n",
       " 'Wild-caught specimens have greater difficulty adapting to a captive environment, which can result in refusal to feed, and they generally carry internal or external parasites.',\n",
       " 'Specimens have survived for up to 60 years in captivity, with the oldest recorded ball python being kept in captivity 62 years, 59 of those at the Saint Louis Zoo.',\n",
       " 'Although the popularity of python breeding has led to more captive-bred ball python pets, it is often cheaper to import them from the wild, and tens of thousands are exported from West Africa each year.',\n",
       " 'The conservational impact on the native population is not well documented.',\n",
       " 'Most captive ball pythons accept common rats and mice, and some eat birds, such as chicken and quail.',\n",
       " 'Some keepers feed their ball pythons multimammate mice, which ball pythons would naturally feed on in the wild.',\n",
       " 'Feeder animals are typically sold frozen and thawed by owners to feed to their pythons.',\n",
       " \"Another option for feeding ball pythons is with live food, where the prey is purchased alive and is either killed by the owner and immediately offered to the snake, or set loose and allowed to be 'hunted' by the snake.\",\n",
       " 'Live feeding is rarely used in some areas, such as the United Kingdom, where, while not expressly prohibited, is considered a legal gray area due to animal welfare laws which prohibit the suffering of vertebrates.',\n",
       " \"It is generally not recommended to allow the snake to 'hunt' its food as the prey's defensive instinct can cause the prey to fight back, causing injury, and even death to the snake.\",\n",
       " 'Younger ball pythons may eat as often as every 5 days, but as they mature, ball pythons tend to wait longer between meals, ranging between 7 and 14 days as adults.',\n",
       " 'A ball python will typically not eat when it is shedding.',\n",
       " '\\n\\n\\n===',\n",
       " 'Breeding ===\\n',\n",
       " 'Ball pythons are one of the most common reptiles bred in captivity.',\n",
       " 'They usually are able to produce a clutch of six eggs on average, but clutch sizes also range from one to eleven.',\n",
       " 'Ball pythons reach sexual maturity at the age of two to two and a half years and a weight of 1500 grams.',\n",
       " 'These snakes usually lay one clutch per year and the eggs hatch around sixty days later.',\n",
       " 'Usually, these eggs are artificially incubated in a captive environment at temperatures between 88–90 degrees Fahrenheit.',\n",
       " 'Some captive breeders use ultra-sounding technology to verify the progress of reproductive development.',\n",
       " 'This can help to increase the chances of successful fertilization as the ultra-sound can help predict the best times to introduce males and females during the breeding season.',\n",
       " 'In captivity, ball pythons are often bred for specific patterns, or morphs.',\n",
       " 'While most of them are solely cosmetic, some have come under controversy due to inherited physical or cognitive defects associated with the inherited pattern.',\n",
       " \"It has been shown that the spider morph gene is connected with major neurological issues, specifically related to the snake's sense of balance.\",\n",
       " 'The International Herpetological Society banned the sale of such morphs at their events.',\n",
       " '\\n',\n",
       " 'Captive ball pythons are available in hundreds of different color patterns.',\n",
       " 'Some of the most common are pastel, albino, mojave, banana,  lesser, and axanthic.',\n",
       " 'Breeders are continuously creating new designer morphs, and over 6,500 different morphs currently exist.',\n",
       " '\\n\\n\\n===',\n",
       " 'General husbandry ===\\n',\n",
       " 'While ball pythons can make excellent pets for those unfamiliar with keeping snakes as a pet, ball pythons still require specialized care and attention.\\n',\n",
       " 'Over the course of their life, a ball python requires a number of different sizes of enclosure in order to meet its needs as it grows; their enclosures can consist of designated reptile terrariums, plastic tubs, or aquarium tanks.',\n",
       " 'Ball pythons can be adept at escaping from their enclosures, meaning that their habitat should be kept secure so as to prevent escape.\\n',\n",
       " \"The snake's enclosure should be kept well-ventilated, and it is recommended that the snake be able to stretch out fully within its enclosure without having to bend or curl up to fit; many keepers recommend a 30–50-gallon tank for an adult ball python.\",\n",
       " 'It is also recommended that ball pythons have some form of enrichment in their enclosure, generally defined as something that allows the snake to exhibit behaviors they would naturally display in the wild, such as exploration.',\n",
       " 'This can be something as simple as fake leaves and/or a cardboard roll, or a more extensive form of enrichment, such as live plants and sculpted backgrounds that allow the snake to climb.',\n",
       " \"Enrichment is considered important, as captivity generally does not provide the same level of activity or positive stimulation as a ball python's natural habitat, and so must be added in by the keeper.\",\n",
       " \"Enrichment is generally thought to improve a captive snake's general health and wellbeing.\",\n",
       " 'In the wild, ball pythons are naturally found in tropical areas with relatively high temperatures, and as such, should be kept in a thermoregulated enclosure.',\n",
       " 'Because snakes rely on their environment for thermoregulation, there should be a range of temperatures throughout the enclosure; this is best achieved with a heat mat placed underneath the enclosure, monitored with a thermostat.',\n",
       " \"It is recommended that one side of the snake's enclosure stay at roughly 92 °F (33 °C), with the other measuring at roughly 78 °F (26 °C), mimicking shade and direct sunlight and allowing the snake to thermoregulate between the two.\",\n",
       " \"Like most snakes, ball pythons benefit from a 'hide' or a small cave, allowing them to the ability to retreat from the 'open ground' of their enclosure; this may simply be an upturned plastic bowl with a small entryway cut into it.\",\n",
       " \"It is recommended that ball pythons have a 'hide' on both the hot and cool sides of the temperature gradient so that they don't have to choose between a comfortable temperature and a safe, dark place, as they are nocturnal and prefer to sleep in the day.\",\n",
       " \"The humidity of a ball python's enclosure should be kept around 50-60%.\",\n",
       " 'This mimics the natural environment of the ball python.',\n",
       " 'During shed, the humidity should be closer to 70-80% to assist the snake in shedding, allowing them to remove their skin entirely on their own.',\n",
       " '\\n',\n",
       " \"A ball python's enclosure is usually filled with a small layer of substrate – an earth-like substance allowing the snake to move easily through friction with the substrate itself, and also assisting in shedding by giving the snake something to rub against to help loosen dead skin.\",\n",
       " \"Substrate can consist of coconut husk and mulch, though paper towels and newspapers are also used; substrate choices must be considered as the type of substrate chosen for a ball python's environment will have an effect on the humidity of the enclosure.\",\n",
       " '\\n',\n",
       " 'Bioactive enclosures imitate a natural environment and are becoming increasingly popular with ball python keepers.',\n",
       " \"Bioactive enclosures rely on the inclusion of elements such as live plants, leaf litter, moss, and 'custodians' in the form of springtails and isopods such as tropical woodlice to mimic an ecosystem in the enclosure.\",\n",
       " \"The 'custodians' live in the substrate – typically a mixture of coconut husk and natural soil – and help to break down waste produced by the snake, including shed skin, which can help with cleanliness and upkeep.\",\n",
       " '\\n\\n\\n==',\n",
       " 'In culture =',\n",
       " '=\\n',\n",
       " 'The ball python is particularly revered by the Igbo people in southeastern Nigeria, who consider it symbolic of the earth, being an animal that travels so close to the ground.',\n",
       " \"Even Christian Igbos treat ball pythons with great care whenever they come across one in a village or on someone's property; they either let them roam or pick them up gently and return them to a forest or field away from houses.\",\n",
       " \"If one is accidentally killed, many communities on Igbo land still build a coffin for the snake's remains and give it a short funeral.\",\n",
       " 'In northwestern Ghana, there is a taboo towards pythons as people consider them a savior and cannot hurt or eat them.',\n",
       " 'According to folklore a python once helped them flee from their enemies by transforming into a log to allow them to cross a river.',\n",
       " '\\n\\n\\n=',\n",
       " '=',\n",
       " 'Gallery ==',\n",
       " '\\n\\n\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\n\\n\\n== References ==\\n\\n\\n==',\n",
       " 'External links ==\\n',\n",
       " '\"Python regius\".',\n",
       " 'Integrated Taxonomic Information System.',\n",
       " 'Retrieved 12 September 2007.',\n",
       " '\\n',\n",
       " 'Python regius at the Reptarium.cz Reptile Database.',\n",
       " 'Accessed 12 September 2007.',\n",
       " '\\n',\n",
       " '\"Ball Python Articles and Care Sheets\".',\n",
       " 'rcreptiles.',\n",
       " '\\n',\n",
       " '\"Ball Python Care and Husbandry\".',\n",
       " 'Ball Python Care Net.\\n',\n",
       " '\"Ball Python Care Sheet\".',\n",
       " 'Archived from the original on 25 April 2012.',\n",
       " 'Retrieved 20 March 2011.',\n",
       " '\\n',\n",
       " '\"Troubleshooting Guide for Ball Pythons\".',\n",
       " '\\n',\n",
       " '\"Ball Pythons as Pets\".',\n",
       " 'Exotic Pets.\\n',\n",
       " '\"Ball Python, Python regius Care\".',\n",
       " 'reptileexpert.',\n",
       " '\\n',\n",
       " '\"Royal Python, Python regius Care\".',\n",
       " 'theroyalpython.',\n",
       " '\\n',\n",
       " '\"Exposure to Salmonella\".',\n",
       " 'CDC.',\n",
       " '\\n',\n",
       " '\"Ball Python care sheet\".',\n",
       " 'allanspetcenter.',\n",
       " '\\n',\n",
       " '\"Morphmarket Reptile Community\".',\n",
       " 'Morphmarket.',\n",
       " 'Python is an interpreted high-level general-purpose programming language.',\n",
       " \"Python's design philosophy emphasizes code readability with its notable use of significant indentation.\",\n",
       " 'Its language constructs as well as its object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.',\n",
       " 'Python is dynamically-typed and garbage-collected.',\n",
       " 'It supports multiple programming paradigms, including structured (particularly, procedural), object-oriented and functional programming.',\n",
       " 'Python is often described as a \"batteries included\" language due to its comprehensive standard library.',\n",
       " 'Guido van Rossum began working on Python in the late 1980s, as a successor to the ABC programming language, and first released it in 1991 as Python 0.9.0.',\n",
       " 'Python 2.0 was released in 2000 and introduced new features, such as list comprehensions and a garbage collection system using reference counting.',\n",
       " 'Python 3.0 was released in 2008 and was a major revision of the language that is not completely backward-compatible and much Python 2 code does not run unmodified on Python 3.',\n",
       " 'Python 2 was discontinued with version 2.7.18 in 2020.Python consistently ranks as one of the most popular programming languages.',\n",
       " '\\n\\n\\n==',\n",
       " 'History ==\\n\\n',\n",
       " 'Python was conceived in the late 1980s by Guido van Rossum at Centrum Wiskunde & Informatica (CWI) in the Netherlands as a successor to  ABC programming language, which was inspired by SETL, capable of exception handling and interfacing with the Amoeba operating system.',\n",
       " 'Its implementation began in December 1989.',\n",
       " 'Van Rossum shouldered sole responsibility for the project, as the lead developer, until 12 July 2018, when he announced his \"permanent vacation\" from his responsibilities as Python\\'s Benevolent Dictator For Life, a title the Python community bestowed upon him to reflect his long-term commitment as the project\\'s chief decision-maker.',\n",
       " 'In January 2019, active Python core developers elected a 5-member \"Steering Council\" to lead the project.',\n",
       " 'As of 2021, the current members of this council are Barry Warsaw, Brett Cannon, Carol Willing, Thomas Wouters, and Pablo Galindo Salgado.',\n",
       " 'Python 2.0 was released on 16 October 2000, with many major new features, including a cycle-detecting garbage collector and support for Unicode.',\n",
       " 'Python 3.0 was released on 3 December 2008.',\n",
       " 'It was a major revision of the language that is not completely backward-compatible.',\n",
       " 'Many of its major features were backported to Python 2.6.x and 2.7.x version series.',\n",
       " \" Releases of Python 3 include the 2to3 utility, which automates (at least partially) the translation of Python 2 code to Python 3.Python 2.7's end-of-life date was initially set at 2015 then postponed to 2020 out of concern that a large body of existing code could not easily be forward-ported to Python 3.  \",\n",
       " 'No more security patches or other improvements will be released for it.',\n",
       " \"With Python 2's end-of-life, only  Python 3.6.x and later are supported.\",\n",
       " '\\n',\n",
       " 'Python 3.9.2 and 3.8.8 were expedited as all versions of Python (including 2.7) had security issues, leading to possible remote code execution and web cache poisoning.',\n",
       " '\\n\\n\\n==',\n",
       " 'Design philosophy and features ==\\n',\n",
       " 'Python is a multi-paradigm programming language.',\n",
       " 'Object-oriented programming and structured programming are fully supported, and many of its features support functional programming and aspect-oriented programming (including by metaprogramming and metaobjects (magic methods)).',\n",
       " 'Many other paradigms are supported via extensions, including design by contract and logic programming.',\n",
       " 'Python uses dynamic typing and a combination of reference counting and a cycle-detecting garbage collector for memory management.',\n",
       " 'It also features dynamic name resolution (late binding), which binds method and variable names during program execution.',\n",
       " '\\n',\n",
       " \"Python's design offers some support for functional programming in the Lisp tradition.\",\n",
       " 'It has filter,mapandreduce functions; list comprehensions, dictionaries, sets, and generator expressions.',\n",
       " \"The standard library has two modules (itertools and functools) that implement functional tools borrowed from Haskell and Standard ML.The language's core philosophy is summarized in the document The Zen of Python (PEP 20), which includes aphorisms such as:\\nBeautiful is better than ugly.\",\n",
       " '\\n',\n",
       " 'Explicit is better than implicit.',\n",
       " '\\n',\n",
       " 'Simple is better than complex.',\n",
       " '\\n',\n",
       " 'Complex is better than complicated.',\n",
       " '\\n',\n",
       " 'Readability counts.',\n",
       " 'Rather than having all of its functionality built into its core, Python was designed to be highly extensible (with modules).',\n",
       " 'This compact modularity has made it particularly popular as a means of adding programmable interfaces to existing applications.',\n",
       " \"Van Rossum's vision of a small core language with a large standard library and easily extensible interpreter stemmed from his frustrations with ABC, which espoused the opposite approach.\",\n",
       " 'Python strives for a simpler, less-cluttered syntax and grammar while giving developers a choice in their coding methodology.',\n",
       " 'In contrast to Perl\\'s \"there is more than one way to do it\" motto, Python embraces a \"there should be one— and preferably only one —obvious way to do it\" design philosophy.',\n",
       " 'Alex Martelli, a Fellow at the Python Software Foundation and Python book author, writes that \"To describe something as \\'clever\\' is not considered a compliment in the Python culture.',\n",
       " '\"Python\\'s developers strive to avoid premature optimization, and reject patches to non-critical parts of the CPython reference implementation that would offer marginal increases in speed at the cost of clarity.',\n",
       " 'When speed is important, a Python programmer can move time-critical functions to extension modules written in languages such as C, or use PyPy, a just-in-time compiler.',\n",
       " 'Cython is also available, which translates a Python script into C and makes direct C-level API calls into the Python interpreter.',\n",
       " '\\n',\n",
       " \"An important goal of Python's developers is keeping it fun to use.\",\n",
       " \"This is reflected in the language's name—a tribute to the British comedy group Monty Python—and in occasionally playful approaches to tutorials and reference materials, such as examples that refer to spam and eggs (from a famous Monty Python sketch) instead of the standard foo and bar.\",\n",
       " 'A common neologism in the Python community is pythonic, which can have a wide range of meanings related to program style.',\n",
       " \"To say that code is pythonic is to say that it uses Python idioms well, that it is natural or shows fluency in the language, that it conforms with Python's minimalist philosophy and emphasis on readability.\",\n",
       " 'In contrast, code that is difficult to understand or reads like a rough transcription from another programming language is called unpythonic.',\n",
       " 'Users and admirers of Python, especially those considered knowledgeable or experienced, are often referred to as Pythonistas.',\n",
       " '\\n\\n\\n=',\n",
       " '=',\n",
       " 'Syntax and semantics ==\\n',\n",
       " 'Python is meant to be an easily readable language.',\n",
       " 'Its formatting is visually uncluttered, and it often uses English keywords where other languages use punctuation.',\n",
       " 'Unlike many other languages, it does not use curly brackets to delimit blocks, and semicolons after statements are allowed but are rarely, if ever, used.',\n",
       " 'It has fewer syntactic exceptions and special cases than C or Pascal.',\n",
       " '\\n\\n\\n==',\n",
       " '= Indentation ===\\n\\n',\n",
       " 'Python uses whitespace indentation, rather than curly brackets or keywords, to delimit blocks.',\n",
       " 'An increase in indentation comes after certain statements; a decrease in indentation signifies the end of the current block.',\n",
       " \"Thus, the program's visual structure accurately represents the program's semantic structure.\",\n",
       " \"This feature is sometimes termed the off-side rule, which some other languages share, but in most languages indentation doesn't have any semantic meaning.\",\n",
       " 'The recommended indent size is four spaces.',\n",
       " '\\n\\n\\n==',\n",
       " '=',\n",
       " 'Statements and control flow ===\\n',\n",
       " \"Python's statements include (among others):\\n\\nThe assignment statement, using a single equals sign =.\",\n",
       " '\\n',\n",
       " 'The if statement, which conditionally executes a block of code, along with else and elif (a contraction of else-if).',\n",
       " '\\n',\n",
       " 'The for statement, which iterates over an iterable object, capturing each element to a local variable for use by the attached block.',\n",
       " '\\n',\n",
       " 'The while statement, which executes a block of code as long as its condition is true.',\n",
       " '\\n',\n",
       " 'The try statement, which allows exceptions raised in its attached code block to be caught and handled by except clauses; it also ensures that clean-up code in a finally block will always be run regardless of how the block exits.',\n",
       " '\\n',\n",
       " 'The raise statement, used to raise a specified exception or re-raise a caught exception.',\n",
       " '\\n',\n",
       " 'The class statement, which executes a block of code and attaches its local namespace to a class, for use in object-oriented programming.',\n",
       " '\\n',\n",
       " 'The def statement, which defines a function or method.',\n",
       " '\\n',\n",
       " 'The with statement, which encloses a code block within a context manager (for example, acquiring a lock before the block of code is run and releasing the lock afterwards, or opening a file and then closing it), allowing resource-acquisition-is-initialization (RAII)-like behavior and replaces a common try/finally idiom.',\n",
       " '\\n',\n",
       " 'The break statement, exits from a loop.',\n",
       " '\\n',\n",
       " 'The continue statement, skips this iteration and continues with the next item.',\n",
       " '\\n',\n",
       " 'The del statement, removes a variable, which means the reference from the name to the value is deleted and trying to use that variable will cause an error.',\n",
       " 'A deleted variable can be reassigned.',\n",
       " '\\n',\n",
       " 'The pass statement, which serves as a NOP.',\n",
       " 'It is syntactically needed to create an empty code block.',\n",
       " '\\n',\n",
       " 'The assert statement, used during debugging to check for conditions that should apply.',\n",
       " '\\n',\n",
       " 'The yield statement, which returns a value from a generator function and yield is also an operator.',\n",
       " 'This form is used to implement coroutines.',\n",
       " '\\n',\n",
       " 'The return statement, used to return a value from a function.',\n",
       " '\\n',\n",
       " 'The import statement, which is used to import modules whose functions or variables can be used in the current program.',\n",
       " 'The assignment statement (=) operates by binding a name as a reference to a separate, dynamically-allocated object.',\n",
       " 'Variables may be subsequently rebound at any time to any object.',\n",
       " \"In Python, a variable name is a generic reference holder and doesn't have a fixed data type associated with it.\",\n",
       " 'However at a given time, a variable will refer to some object, which will have a type.',\n",
       " 'This is referred to as dynamic typing and is contrasted with statically-typed programming languages, where each variable may only contain values of a certain type.',\n",
       " '\\n',\n",
       " 'Python does not support tail call optimization or first-class continuations, and, according to Guido van Rossum, it never will.',\n",
       " \"However, better support for coroutine-like functionality is provided, by extending Python's generators.\",\n",
       " 'Before 2.5, generators were lazy iterators; information was passed unidirectionally out of the generator.',\n",
       " 'From Python 2.5, it is possible to pass information back into a generator function, and from Python 3.3, the information can be passed through multiple stack levels.',\n",
       " '\\n\\n\\n===',\n",
       " 'Expressions ===\\n',\n",
       " 'Some Python expressions are similar to those found in languages such as C and Java, while some are not:\\n\\nAddition, subtraction, and multiplication are the same, but the behavior of division differs.',\n",
       " 'There are two types of divisions in Python.',\n",
       " 'They are floor division (or integer division) // and floating-point/division.',\n",
       " 'Python also uses the ** operator for exponentiation.',\n",
       " '\\n',\n",
       " 'From Python 3.5, the new @ infix operator was introduced.',\n",
       " 'It is intended to be used by libraries such as NumPy for matrix multiplication.',\n",
       " '\\n',\n",
       " \"From Python 3.8, the syntax :=, called the 'walrus operator' was introduced.\",\n",
       " 'It assigns values to variables as part of a larger expression.',\n",
       " '\\n',\n",
       " 'In Python, == compares by value, versus Java, which compares numerics by value and objects by reference.',\n",
       " '(Value comparisons in Java on objects can be performed with the equals() method.)',\n",
       " \"Python's is operator may be used to compare object identities (comparison by reference).\",\n",
       " 'In Python, comparisons may be chained, for example a <= b <= c.\\n',\n",
       " 'Python uses the words and, or, not for its boolean operators rather than the symbolic &&, ||, ! used in Java and C.',\n",
       " '\\nPython has a type of expression termed a list comprehension as well as a more general expression termed a generator expression.',\n",
       " '\\n',\n",
       " 'Anonymous functions are implemented using lambda expressions; however, these are limited in that the body can only be one expression.',\n",
       " '\\n',\n",
       " 'Conditional expressions in Python are written as x if c else y (different in order of operands from the c ?',\n",
       " 'x : y operator common to many other languages).',\n",
       " '\\n',\n",
       " 'Python makes a distinction between lists and tuples.',\n",
       " 'Lists are written as [1, 2, 3], are mutable, and cannot be used as the keys of dictionaries (dictionary keys must be immutable in Python).',\n",
       " 'Tuples are written as (1, 2, 3), are immutable and thus can be used as the keys of dictionaries, provided all elements of the tuple are immutable.',\n",
       " 'The + operator can be used to concatenate two tuples, which does not directly modify their contents, but rather produces a new tuple containing the elements of both provided tuples.',\n",
       " 'Thus, given the variable t initially equal to (1, 2, 3), executing t = t + (4, 5) first evaluates t + (4, 5), which yields (1, 2, 3, 4, 5), which is then assigned back to t, thereby effectively \"modifying the contents\" of t, while conforming to the immutable nature of tuple objects.',\n",
       " 'Parentheses are optional for tuples in unambiguous contexts.',\n",
       " '\\n',\n",
       " 'Python features sequence unpacking wherein multiple expressions, each evaluating to anything that can be assigned to (a variable, a writable property, etc.), are associated in an identical manner to that forming tuple literals and, as a whole, are put on the left-hand side of the equal sign in an assignment statement.',\n",
       " 'The statement expects an iterable object on the right-hand side of the equal sign that produces the same number of values as the provided writable expressions when iterated through and will iterate through it, assigning each of the produced values to the corresponding expression on the left.',\n",
       " '\\n',\n",
       " 'Python has a \"string format\" operator %.',\n",
       " 'This functions analogously to printf format strings in C, e.g. \"spam=%s eggs=%d\" % (\"blah\", 2) evaluates to \"spam=blah eggs=2\".',\n",
       " 'In Python 3 and 2.6+, this was supplemented by the format() method of the str class, e.g. \"spam={0} eggs={1}\".format(\"blah\", 2).',\n",
       " 'Python 3.6 added \"f-strings\": blah = \"blah\"; eggs = 2; f\\'spam={blah} eggs={eggs}\\'.',\n",
       " '\\n',\n",
       " 'Strings in Python can be concatenated, by \"adding\" them (same operator as for adding integers and floats).',\n",
       " 'E.g. \"spam\" + \"eggs\" returns \"spameggs\".',\n",
       " 'Even if your strings contain numbers, they are still added as strings rather than integers.',\n",
       " 'E.g. \"2\" + \"2\" returns \"22\".',\n",
       " '\\n',\n",
       " 'Python has various kinds of string literals:\\nStrings delimited by single or double quote marks.',\n",
       " 'Unlike in Unix shells, Perl and Perl-influenced languages, single quote marks and double quote marks function identically.',\n",
       " 'Both kinds of string use the backslash (\\\\) as an escape character.',\n",
       " 'String interpolation became available in Python 3.6 as \"formatted string literals\".',\n",
       " '\\n',\n",
       " 'Triple-quoted strings, which begin and end with a series of three single or double quote marks.',\n",
       " 'They may span multiple lines and function like here documents in shells, Perl and Ruby.',\n",
       " '\\n',\n",
       " 'Raw string varieties, denoted by prefixing the string literal with an r. Escape sequences are not interpreted; hence raw strings are useful where literal backslashes are common, such as regular expressions and Windows-style paths.',\n",
       " 'Compare \"@-quoting\" in C#.',\n",
       " '\\n',\n",
       " 'Python has array index and array slicing expressions on lists, denoted as a[key], a[start:stop] or a[start:stop:step].',\n",
       " 'Indexes are zero-based, and negative indexes are relative to the end.',\n",
       " 'Slices take elements from the start index up to, but not including, the stop index.',\n",
       " 'The third slice parameter, called step or stride, allows elements to be skipped and reversed.',\n",
       " 'Slice indexes may be omitted, for example a[:] returns a copy of the entire list.',\n",
       " 'Each element of a slice is a shallow copy.',\n",
       " 'In Python, a distinction between expressions and statements is rigidly enforced, in contrast to languages such as Common Lisp, Scheme, or Ruby.',\n",
       " 'This leads to duplicating some functionality.',\n",
       " 'For example:\\n\\nList comprehensions vs. for-loops\\nConditional expressions vs. if blocks\\nThe eval() vs. exec() built-in functions (in Python 2, exec is a statement); the former is for expressions, the latter is for statements.',\n",
       " 'Statements cannot be a part of an expression, so list and other comprehensions or lambda expressions, all being expressions, cannot contain statements.',\n",
       " 'A particular case of this is that an assignment statement such as a = 1 cannot form part of the conditional expression of a conditional statement.',\n",
       " 'This has the advantage of avoiding a classic C error of mistaking an assignment operator = for an equality operator == in conditions: if (c = 1) { ... } is syntactically valid (but probably unintended) C code',\n",
       " 'but if c = 1: ... causes a syntax error in Python.',\n",
       " '\\n\\n\\n===',\n",
       " 'Methods ===\\n',\n",
       " \"Methods on objects are functions attached to the object's class; the syntax instance.method(argument) is, for normal methods and functions, syntactic sugar for Class.method(instance, argument).\",\n",
       " 'Python methods have an explicit self parameter to access instance data, in contrast to the implicit self (or this) in some other object-oriented programming languages (e.g., C++, Java, Objective-C, or Ruby).',\n",
       " '\\n\\n\\n===',\n",
       " 'Typing ===\\n\\n',\n",
       " 'Python uses duck typing and has typed objects but untyped variable names.',\n",
       " 'Type constraints are not checked at compile time; rather, operations on an object may fail, signifying that the given object is not of a suitable type.',\n",
       " 'Despite being dynamically-typed, Python is strongly-typed, forbidding operations that are not well-defined (for example, adding a number to a string) rather than silently attempting to make sense of them.',\n",
       " '\\n',\n",
       " 'Python allows programmers to define their own types using classes, which are most often used for object-oriented programming.',\n",
       " 'New instances of classes are constructed by calling the class (for example, SpamClass() or EggsClass()), and the classes are instances of the metaclass type (itself an instance of itself), allowing metaprogramming and reflection.',\n",
       " '\\n',\n",
       " 'Before version 3.0, Python had two kinds of classes: old-style and new-style.',\n",
       " 'The syntax of both styles is the same, the difference being whether the class object is inherited from, directly or indirectly (all new-style classes inherit from object and are instances of type).',\n",
       " 'In versions of Python 2 from Python 2.2 onwards, both kinds of classes can be used.',\n",
       " 'Old-style classes were eliminated in Python 3.0.',\n",
       " '\\n',\n",
       " 'The long-term plan is to support gradual typing and from Python 3.5, the syntax of the language allows specifying static types but they are not checked in the default implementation, CPython.',\n",
       " 'An experimental optional static type checker named mypy supports compile-time type checking.',\n",
       " '\\n^a',\n",
       " 'Not directly accessible by name \\n\\n\\n===',\n",
       " 'Arithmetic operations ===\\n',\n",
       " 'Python has the usual symbols for arithmetic operators (+, -, *, /), the floor division operator // and the modulo operation % (where the remainder can be negative,  e.g. 4 % -3 == -2).',\n",
       " 'It also has ** for exponentiation, e.g. 5**3 == 125 and 9**0.5 == 3.0, and a matrix multiply operator @ .',\n",
       " 'These operators work like in traditional math; with the same precedence rules, the operators infix ( + and - can also be unary to represent positive and negative numbers respectively).',\n",
       " '\\n',\n",
       " 'The division between integers produces floating-point results.',\n",
       " 'The behavior of division has changed significantly over time:\\n',\n",
       " \"Python 2.1 and earlier used C's division behavior.\",\n",
       " 'The / operator is integer division if both operands are integers, and floating-point division otherwise.',\n",
       " 'Integer division rounds towards 0, e.g. 7/3 == 2 and -7/3 == -2.',\n",
       " '\\n',\n",
       " 'Python 2.2 changed integer division to round towards negative infinity, e.g. 7/3 == 2 and -7/3 == -3.',\n",
       " 'The floor division // operator was introduced.',\n",
       " 'So 7//3 == 2, -7//3 ==',\n",
       " '-3',\n",
       " ', 7.5//3 == 2.0 and -7.5//3 == -3.0.',\n",
       " 'Adding from __future__ import division causes a module to use Python 3.0 rules for division (see next).',\n",
       " '\\n',\n",
       " 'Python 3.0 changed / to always be floating-point division, e.g. 5/2 ==',\n",
       " '2.5.In Python terms, / is true division (or simply division), and // is floor division.',\n",
       " '/ before version 3.0 is classic division.',\n",
       " 'Rounding towards negative infinity, though different from most languages, adds consistency.',\n",
       " 'For instance, it means that the equation (a + b)//b ==',\n",
       " 'a//b + 1 is always true.',\n",
       " 'It also means that the equation b*(a//b)',\n",
       " '+ a%b == a is valid for both positive and negative values of a. However, maintaining the validity of this equation means that while the result of a%b is, as expected, in the half-open interval [0, b), where b is a positive integer, it has to lie in the interval (b, 0] when b is negative.',\n",
       " 'Python provides a round function for rounding a float to the nearest integer.',\n",
       " 'For tie-breaking, Python 3 uses round to even: round(1.5) and round(2.5) both produce 2.',\n",
       " 'Versions before 3 used round-away-from-zero: round(0.5) is 1.0, round(-0.5) is −1.0.Python allows boolean expressions with multiple equality relations in a manner that is consistent with general use in mathematics.',\n",
       " 'For example, the expression a < b < c tests whether a is less than b and b is less than c. C-derived languages interpret this expression differently: in C, the expression would first evaluate a < b, resulting in 0 or 1, and that result would then be compared with c.Python uses arbitrary-precision arithmetic for all integer operations.',\n",
       " 'The Decimal type/class in the decimal module provides decimal floating-point numbers to a pre-defined arbitrary precision and several rounding modes.',\n",
       " 'The Fraction class in the fractions module provides arbitrary precision for rational numbers.',\n",
       " \"Due to Python's extensive mathematics library, and the third-party library NumPy that further extends the native capabilities, it is frequently used as a scientific scripting language to aid in problems such as numerical data processing and manipulation.\",\n",
       " '\\n\\n\\n==',\n",
       " 'Programming examples ==\\n',\n",
       " 'Hello world program:\\n\\nProgram to calculate the factorial of a positive integer:\\n\\n\\n==',\n",
       " 'Libraries ==\\n',\n",
       " \"Python's large standard library, commonly cited as one of its greatest strengths, provides tools suited to many tasks.\",\n",
       " 'For Internet-facing applications, many standard formats and protocols such as MIME and HTTP are supported.',\n",
       " 'It includes modules for creating graphical user interfaces, connecting to relational databases, generating pseudorandom numbers, arithmetic with arbitrary-precision decimals, manipulating regular expressions, and unit testing.',\n",
       " '\\n',\n",
       " 'Some parts of the standard library are covered by specifications (for example, the Web Server Gateway Interface (WSGI) implementation wsgiref follows PEP 333), but most modules are not.',\n",
       " 'They are specified by their code, internal documentation, and test suites.',\n",
       " 'However, because most of the standard library is cross-platform Python code, only a few modules need altering or rewriting for variant implementations.',\n",
       " '\\n',\n",
       " 'As of March 2021, the Python Package Index (PyPI), the official repository for third-party Python software, contains over 290,000 packages with a wide range of functionality, including:\\n\\n\\n==',\n",
       " 'Development environments ==\\n\\nMost Python implementations (including CPython) include a read–eval–print loop (REPL), permitting them to function as a command line interpreter for which the user enters statements sequentially and receives results immediately.',\n",
       " '\\n',\n",
       " 'Other shells, including IDLE and IPython, add further abilities such as improved auto-completion, session state retention and syntax highlighting.',\n",
       " '\\n',\n",
       " 'As well as standard desktop integrated development environments, there are Web browser-based IDEs; SageMath (intended for developing science and math-related Python programs);',\n",
       " 'PythonAnywhere, a browser-based IDE and hosting environment; and Canopy IDE, a commercial Python IDE emphasizing scientific computing.',\n",
       " '\\n\\n\\n==',\n",
       " 'Implementations ==\\n\\n\\n===',\n",
       " 'Reference implementation ===\\n',\n",
       " 'CPython is the reference implementation of Python.',\n",
       " \"It is written in C, meeting the C89 standard with several select C99 features (with later C versions out, it's considered outdated;  CPython includes its own C extensions, but third-party extensions are not limited to older C versions, can e.g. be implemented with C11 or C++).\",\n",
       " 'It compiles Python programs into an intermediate bytecode which is then executed by its virtual machine.',\n",
       " 'CPython is distributed with a large standard library written in a mixture of C and native Python.',\n",
       " 'It is available for many platforms, including Windows (starting with Python 3.9, the Python installer deliberately fails to install on Windows 7 and 8; Windows XP was supported until Python 3.5) and most modern Unix-like systems, including macOS (and Apple M1 Macs, since Python 3.9.1, with experimental installer) and unofficial support for e.g. VMS.',\n",
       " 'Platform portability was one of its earliest priorities, during the Python 1 and 2 time-frame, even OS/2 and Solaris were supported; support has since been dropped for a lot of platforms.',\n",
       " '\\n\\n\\n==',\n",
       " '=',\n",
       " 'Other implementations ===\\n',\n",
       " 'PyPy is a fast, compliant interpreter of Python 2.7 and 3.6.',\n",
       " 'Its just-in-time compiler brings a significant speed improvement over CPython but several libraries written in C cannot be used with it.',\n",
       " '\\n',\n",
       " 'Stackless Python is a significant fork of CPython that implements microthreads; it does not use the call stack in the same way, thus allowing massively concurrent programs.',\n",
       " 'PyPy also has a stackless version.',\n",
       " '\\n',\n",
       " 'MicroPython and CircuitPython are Python 3 variants optimized for microcontrollers, including Lego Mindstorms EV3.',\n",
       " '\\n',\n",
       " 'Pyston is a variant of the Python runtime that uses just-in-time compilation to speed up the execution of Python programs.',\n",
       " '\\n',\n",
       " 'Cinder is a performance-oriented fork of CPython 3.8 that contains a number of optimizations including bytecode inline caching, eager evaluation of coroutines, a method-at-a-time JIT and an experimental bytecode compiler.',\n",
       " '\\n\\n\\n==',\n",
       " '=',\n",
       " 'Unsupported implementations ===\\n',\n",
       " 'Other just-in-time Python compilers have been developed, but are now unsupported:\\n\\nGoogle began a project named Unladen Swallow in 2009, with the aim of speeding up the Python interpreter fivefold by using the LLVM, and of improving its multithreading ability to scale to thousands of cores, while ordinary implementations suffer from the global interpreter lock.',\n",
       " '\\n',\n",
       " 'Psyco is a discontinued just-in-time specializing compiler that integrates with CPython and transforms bytecode to machine code at runtime.',\n",
       " 'The emitted code is specialized for certain data types and is faster than the standard Python code.',\n",
       " 'Psyco does not support Python 2.7 or later.',\n",
       " '\\nPyS60 was a Python 2 interpreter for Series 60 mobile phones released by Nokia in 2005.',\n",
       " 'It implemented many of the modules from the standard library and some additional modules for integrating with the Symbian operating system.',\n",
       " 'The Nokia N900 also supports Python with GTK widget libraries, enabling programs to be written and run on the target device.',\n",
       " '\\n\\n\\n==',\n",
       " '=',\n",
       " 'Cross-compilers to other languages ===\\n',\n",
       " 'There are several compilers to high-level object languages, with either unrestricted Python, a restricted subset of Python, or a language similar to Python as the source language:\\n\\nCython compiles (a superset of)',\n",
       " 'Python 2.7 to C (while the resulting code is also usable with Python 3 and also e.g. C++).',\n",
       " '\\n',\n",
       " 'Nuitka compiles Python into C++.',\n",
       " '\\n',\n",
       " 'Pythran compiles a subset of Python 3 to C++.',\n",
       " '\\n',\n",
       " 'Pyrex (latest release in 2010) and Shed Skin (latest release in 2013) compile to C and C++ respectively.',\n",
       " '\\n',\n",
       " \"Google's Grumpy (latest release in 2017) transpiles Python 2 to Go.\",\n",
       " '\\n',\n",
       " 'IronPython (now abandoned by Microsoft) allows running Python 2.7 programs on the .NET',\n",
       " 'Common Language Runtime.',\n",
       " '\\n',\n",
       " 'Jython compiles Python 2.7 to Java bytecode, allowing the use of the Java libraries from a Python program.',\n",
       " '\\n',\n",
       " 'MyHDL is a Python-based hardware description language (HDL), that converts MyHDL code to Verilog or VHDL code.',\n",
       " '\\n',\n",
       " 'Numba uses LLVM to compile a subset of Python to machine code.',\n",
       " '\\n',\n",
       " 'Brython, Transcrypt and Pyjs (latest release in 2012) compile Python to JavaScript.',\n",
       " '\\n',\n",
       " 'RPython can be compiled to C, and is used to build the PyPy interpreter of Python.',\n",
       " '\\n\\n\\n===',\n",
       " 'Performance ===\\n',\n",
       " \"A performance comparison of various Python implementations on a non-numerical (combinatorial) workload was presented at EuroSciPy '13.\",\n",
       " \"Python's performance compared to other programming languages is also benchmarked by The Computer Language Benchmarks Game.\",\n",
       " '\\n\\n\\n==',\n",
       " 'Development ==\\n',\n",
       " \"Python's development is conducted largely through the Python Enhancement Proposal (PEP) process, the primary mechanism for proposing major new features, collecting community input on issues and documenting Python design decisions.\",\n",
       " 'Python coding style is covered in PEP 8.',\n",
       " 'Outstanding PEPs are reviewed and commented on by the Python community and the steering council.',\n",
       " 'Enhancement of the language corresponds with development of the CPython reference implementation.',\n",
       " \"The mailing list python-dev is the primary forum for the language's development.\",\n",
       " 'Specific issues are discussed in the Roundup bug tracker hosted at bugs.python.org.',\n",
       " \"Development originally took place on a self-hosted source-code repository running Mercurial, until Python moved to GitHub in January 2017.CPython's public releases come in three types, distinguished by which part of the version number is incremented:\\n\\nBackward-incompatible versions, where code is expected to break and needs to be manually ported.\",\n",
       " 'The first part of the version number is incremented.',\n",
       " 'These releases happen infrequently—version 3.0 was released 8 years after 2.0.',\n",
       " '\\n',\n",
       " 'Major or \"feature\" releases, occurred about every 18 months but with the adoption of a yearly release cadence starting with Python 3.9 are expected to happen once a year.',\n",
       " 'They are largely compatible but introduce new features.',\n",
       " 'The second part of the version number is incremented.',\n",
       " 'Each major version is supported by bugfixes for several years after its release.',\n",
       " '\\n',\n",
       " 'Bugfix releases, which introduce no new features, occur about every 3 months and are made when a sufficient number of bugs have been fixed upstream since the last release.',\n",
       " 'Security vulnerabilities are also patched in these releases.',\n",
       " 'The third and final part of the version number is incremented.',\n",
       " 'Many alpha, beta, and release-candidates are also released as previews and for testing before final releases.',\n",
       " 'Although there is a rough schedule for each release, they are often delayed if the code is not ready.',\n",
       " \"Python's development team monitors the state of the code by running the large unit test suite during development.\",\n",
       " 'The major academic conference on Python is PyCon.',\n",
       " 'There are also special Python mentoring programmes, such as Pyladies.\\n',\n",
       " 'Pythons 3.10 deprecates wstr (to be removed in Python 3.12; meaning Python extensions need to be modified by then), and also plans to add pattern matching to the language.',\n",
       " '\\n\\n\\n== API documentation generators ==\\n',\n",
       " 'Tools that can generate documentation for Python API include pydoc (available as part of standard library), Sphinx, Pdoc and its forks, Doxygen and Graphviz, among others.',\n",
       " '\\n\\n\\n==',\n",
       " 'Naming ==\\n',\n",
       " \"Python's name is derived from the British comedy group Monty Python, whom Python creator Guido van Rossum enjoyed while developing the language.\",\n",
       " 'Monty Python references appear frequently in Python code and culture; for example, the metasyntactic variables often used in Python literature are spam and eggs instead of the traditional foo and bar.',\n",
       " 'The official Python documentation also contains various references to Monty Python routines.',\n",
       " 'The prefix Py- is used to show that something is related to Python.',\n",
       " 'Examples of the use of this prefix in names of Python applications or libraries include Pygame, a binding of SDL to Python (commonly used to create games); PyQt and PyGTK, which bind Qt and GTK to Python respectively; and PyPy, a Python implementation originally written in Python.',\n",
       " '\\n\\n\\n==',\n",
       " 'Popularity ==\\n',\n",
       " 'Since 2003, Python has consistently ranked in the top ten most popular programming languages in the TIOBE Programming Community Index where, as of February 2021, it is the third most popular language (behind Java, and C).',\n",
       " 'It was selected Programming Language of the Year (for \"the highest rise in ratings in a year\") in 2007, 2010, 2018, and 2020 (the only language to do so four times).An empirical study found that scripting languages, such as Python, are more productive than conventional languages, such as C and Java, for programming problems involving string manipulation and search in a dictionary, and determined that memory consumption was often \"better than Java and not much worse than C or C++\".',\n",
       " 'Large organizations that use Python include Wikipedia, Google, Yahoo!, CERN, NASA, Facebook, Amazon, Instagram, Spotify and some smaller entities like ILM and ITA.',\n",
       " 'The social news networking site Reddit was written mostly in Python.',\n",
       " '\\n\\n\\n==',\n",
       " 'Uses ==\\n\\nPython can serve as a scripting language for web applications, e.g., via mod wsgi for the Apache web server.',\n",
       " 'With Web Server Gateway Interface, a standard API has evolved to facilitate these applications.',\n",
       " 'Web frameworks like Django, Pylons, Pyramid, TurboGears, web2py, Tornado, Flask, Bottle and Zope support developers in the design and maintenance of complex applications.',\n",
       " 'Pyjs and IronPython can be used to develop the client-side of Ajax-based applications.',\n",
       " 'SQLAlchemy can be used as a data mapper to a relational database.',\n",
       " 'Twisted is a framework to program communications between computers, and is used (for example) by Dropbox.',\n",
       " '\\n',\n",
       " 'Libraries such as NumPy, SciPy and Matplotlib allow the effective use of Python in scientific computing, with specialized libraries such as Biopython and Astropy providing domain-specific functionality.',\n",
       " 'SageMath is a computer algebra system with a notebook interface programmable in Python: its library covers many aspects of mathematics, including algebra, combinatorics, numerical mathematics, number theory, and calculus.',\n",
       " 'OpenCV has python bindings with a rich set of features for computer vision and image processing.',\n",
       " 'Python is commonly used in artificial intelligence projects and machine learning projects with the help of libraries like TensorFlow, Keras, Pytorch and Scikit-learn.',\n",
       " 'As a scripting language with modular architecture, simple syntax and rich text processing tools, Python is often used for natural language processing.',\n",
       " 'Python has been successfully embedded in many software products as a scripting language, including in finite element method software such as Abaqus, 3D parametric modeler like FreeCAD, 3D animation packages such as 3ds Max, Blender, Cinema 4D, Lightwave, Houdini, Maya, modo, MotionBuilder, Softimage, the visual effects compositor Nuke, 2D imaging programs like GIMP, Inkscape, Scribus and Paint Shop Pro, and musical notation programs like scorewriter and capella.',\n",
       " 'GNU Debugger uses Python as a pretty printer to show complex structures such as C++ containers.',\n",
       " 'Esri promotes Python as the best choice for writing scripts in ArcGIS.',\n",
       " 'It has also been used in several video games, and has been adopted as first of the three available programming languages in Google App Engine, the other two being Java and Go.',\n",
       " 'Many operating systems include Python as a standard component.',\n",
       " 'It ships with most Linux distributions, AmigaOS 4 (using Python 2.7), FreeBSD (as a package), NetBSD, OpenBSD (as a package) and macOS and can be used from the command line (terminal).',\n",
       " 'Many Linux distributions use installers written in Python:',\n",
       " 'Ubuntu uses the Ubiquity installer, while Red Hat Linux and Fedora use the Anaconda installer.',\n",
       " 'Gentoo Linux uses Python in its package management system, Portage.',\n",
       " '\\n',\n",
       " 'Python is used extensively in the information security industry, including in exploit development.',\n",
       " 'Most of the Sugar software for the One Laptop per Child XO, now developed at Sugar Labs, is written in Python.',\n",
       " 'The Raspberry Pi single-board computer project has adopted Python as its main user-programming language.',\n",
       " '\\n',\n",
       " 'LibreOffice includes Python, and intends to replace Java with Python.',\n",
       " 'Its Python Scripting Provider is a core feature since Version 4.0 from 7 February 2013.',\n",
       " '\\n\\n\\n==',\n",
       " 'Languages influenced by Python ==\\n',\n",
       " \"Python's design and philosophy have influenced many other programming languages:\\n\\nBoo uses indentation, a similar syntax, and a similar object model.\",\n",
       " '\\n',\n",
       " 'Cobra uses indentation and a similar syntax, and its Acknowledgements document lists Python first among languages that influenced it.',\n",
       " '\\n',\n",
       " 'CoffeeScript, a programming language that cross-compiles to JavaScript, has Python-inspired syntax.',\n",
       " '\\nECMAScript/JavaScript borrowed iterators and generators from Python.',\n",
       " '\\n',\n",
       " 'GDScript, a scripting language very similar to Python, built-in to the Godot game engine.',\n",
       " '\\n',\n",
       " 'Go is designed for the \"speed of working in a dynamic language like Python\" and shares the same syntax for slicing arrays.',\n",
       " '\\n',\n",
       " 'Groovy was motivated by the desire to bring the Python design philosophy to Java.',\n",
       " '\\n',\n",
       " 'Julia was designed to be \"as usable for general programming as Python\".',\n",
       " '\\n',\n",
       " 'Nim uses indentation and similar syntax.',\n",
       " '\\n',\n",
       " 'Ruby\\'s creator, Yukihiro Matsumoto, has said: \"I wanted a scripting language that was more powerful than Perl, and more object-oriented than Python.',\n",
       " 'That\\'s why I decided to design my own language.\"',\n",
       " '\\nSwift, a programming language developed by Apple, has some Python-inspired syntax.',\n",
       " \"Python's development practices have also been emulated by other languages.\",\n",
       " 'For example, the practice of requiring a document describing the rationale for, and issues surrounding, a change to the language (in Python, a PEP) is also used in Tcl, Erlang, and Swift.',\n",
       " '\\n\\n\\n=',\n",
       " '= See also ==',\n",
       " '\\n\\nPython syntax and semantics\\npip (package manager)',\n",
       " '\\n',\n",
       " 'Differentiable programming\\n\\n\\n==',\n",
       " 'References ==\\n\\n\\n===',\n",
       " 'Sources ===\\n',\n",
       " '\"Python for Artificial Intelligence\".',\n",
       " 'Wiki.python.org.',\n",
       " '19 July 2012.',\n",
       " 'Archived from the original on 1 November 2012.',\n",
       " 'Retrieved 3 December 2012.',\n",
       " '\\n',\n",
       " 'Paine, Jocelyn, ed.',\n",
       " '(August 2005).',\n",
       " '\"AI in Python\".',\n",
       " 'AI Expert Newsletter.',\n",
       " 'Amzi!.',\n",
       " 'Archived from the original on 26 March 2012.',\n",
       " 'Retrieved 11 February 2012.',\n",
       " '\\n\"PyAIML 0.8.5 :',\n",
       " 'Python Package Index\".',\n",
       " 'Pypi.python.org.',\n",
       " 'Retrieved 17 July 2013.',\n",
       " '\\n',\n",
       " 'Russell, Stuart J. & Norvig, Peter (2009).',\n",
       " 'Artificial Intelligence:',\n",
       " 'A Modern Approach (3rd ed.).',\n",
       " 'Upper Saddle River, NJ: Prentice Hall.',\n",
       " 'ISBN 978-0-13-604259-4.',\n",
       " '\\n\\n\\n=',\n",
       " '= Further reading ==\\n',\n",
       " 'Downey, Allen B. (May 2012).',\n",
       " 'Think Python: How to Think Like a Computer Scientist (Version 1.6.6 ed.).',\n",
       " 'ISBN 978-0-521-72596-5.',\n",
       " '\\n',\n",
       " 'Hamilton, Naomi (5 August 2008).',\n",
       " '\"The A-Z of Programming Languages: Python\".',\n",
       " 'Computerworld.',\n",
       " 'Archived from the original on 29 December 2008.',\n",
       " 'Retrieved 31 March 2010.',\n",
       " '\\n',\n",
       " 'Lutz, Mark (2013).',\n",
       " 'Learning Python (5th ed.).',\n",
       " \"O'Reilly Media.\",\n",
       " 'ISBN 978-0-596-15806-4.\\n',\n",
       " 'Pilgrim, Mark (2004).',\n",
       " 'Dive into Python.',\n",
       " 'Apress.',\n",
       " 'ISBN 978-1-59059-356-1.\\n',\n",
       " 'Pilgrim, Mark (2009).',\n",
       " 'Dive into Python 3.',\n",
       " 'Apress.',\n",
       " 'ISBN 978-1-4302-2415-0.',\n",
       " '\\n',\n",
       " 'Summerfield, Mark (2009).',\n",
       " 'Programming in Python 3 (2nd ed.).',\n",
       " 'Addison-Wesley Professional.',\n",
       " 'ISBN 978-0-321-68056-3.',\n",
       " '\\n\\n\\n==',\n",
       " 'External links ==\\n\\n',\n",
       " 'Official website']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 229)\t1\n",
      "  (0, 280)\t1\n",
      "  (0, 1397)\t1\n",
      "  (0, 1582)\t1\n",
      "  (0, 1745)\t1\n",
      "  (0, 2081)\t2\n",
      "  (0, 2212)\t1\n",
      "  (0, 2214)\t1\n",
      "  (0, 2442)\t1\n",
      "  (0, 2443)\t1\n",
      "  (0, 2455)\t1\n",
      "  (0, 2630)\t1\n",
      "  (0, 2669)\t1\n",
      "  (1, 229)\t1\n",
      "  (1, 279)\t1\n",
      "  (1, 347)\t1\n",
      "  (1, 615)\t1\n",
      "  (1, 809)\t1\n",
      "  (1, 1397)\t1\n",
      "  (1, 1403)\t1\n",
      "  (1, 1415)\t1\n",
      "  (1, 1417)\t1\n",
      "  (1, 1495)\t1\n",
      "  (1, 1529)\t1\n",
      "  (1, 1530)\t1\n",
      "  :\t:\n",
      "  (815, 2081)\t1\n",
      "  (816, 255)\t1\n",
      "  (817, 66)\t1\n",
      "  (817, 94)\t1\n",
      "  (817, 134)\t1\n",
      "  (817, 1398)\t1\n",
      "  (819, 51)\t1\n",
      "  (819, 1607)\t1\n",
      "  (819, 2558)\t1\n",
      "  (820, 73)\t1\n",
      "  (820, 862)\t1\n",
      "  (820, 1303)\t1\n",
      "  (820, 2036)\t1\n",
      "  (820, 2081)\t1\n",
      "  (821, 167)\t1\n",
      "  (821, 2030)\t1\n",
      "  (821, 2835)\t1\n",
      "  (822, 79)\t1\n",
      "  (822, 117)\t1\n",
      "  (822, 134)\t1\n",
      "  (822, 1398)\t1\n",
      "  (824, 994)\t1\n",
      "  (824, 1526)\t1\n",
      "  (825, 1827)\t1\n",
      "  (825, 2823)\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<826x2915 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9534 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bag_of_words = CountVectorizer()\n",
    "bag_of_words.fit(documents)\n",
    "word_counts = bag_of_words.transform(documents)\n",
    "\n",
    "print(word_counts)\n",
    "word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 280)\t0.36077127313341345\n",
      "  (0, 2443)\t0.3480564896372768\n",
      "  (0, 229)\t0.12139969348210765\n",
      "  (0, 2442)\t0.36077127313341345\n",
      "  (0, 2669)\t0.13535498654153616\n",
      "  (0, 1745)\t0.3212755481623284\n",
      "  (0, 2455)\t0.3145642370396516\n",
      "  (0, 1397)\t0.15387668026180157\n",
      "  (0, 2214)\t0.3288842051777745\n",
      "  (0, 1582)\t0.3480564896372768\n",
      "  (0, 2081)\t0.2467069894290522\n",
      "  (0, 2212)\t0.23717797173946778\n",
      "  (0, 2630)\t0.11494981478971213\n",
      "  (1, 809)\t0.27291261032186964\n",
      "  (1, 2854)\t0.2578795385261705\n",
      "  (1, 1415)\t0.16828426068769256\n",
      "  (1, 1822)\t0.11062652077025796\n",
      "  (1, 347)\t0.2578795385261705\n",
      "  (1, 1529)\t0.23379798821904416\n",
      "  (1, 2138)\t0.27291261032186964\n",
      "  (1, 1417)\t0.2957355283559717\n",
      "  (1, 1835)\t0.16497322832077918\n",
      "  (1, 615)\t0.282882327471015\n",
      "  (1, 1495)\t0.2578795385261705\n",
      "  (1, 279)\t0.13774717021894356\n",
      "  :\t:\n",
      "  (815, 2081)\t0.2523446549588122\n",
      "  (816, 255)\t1.0\n",
      "  (817, 66)\t0.5463374026179089\n",
      "  (817, 94)\t0.5463374026179089\n",
      "  (817, 134)\t0.44890471427767037\n",
      "  (817, 1398)\t0.44890471427767037\n",
      "  (819, 2558)\t0.641333453333285\n",
      "  (819, 1607)\t0.5576784284270643\n",
      "  (819, 51)\t0.5269593647547438\n",
      "  (820, 73)\t0.6570234304621042\n",
      "  (820, 862)\t0.5542690950141009\n",
      "  (820, 2036)\t0.41018968855798477\n",
      "  (820, 1303)\t0.22771072829982614\n",
      "  (820, 2081)\t0.2024801860773645\n",
      "  (821, 2030)\t0.5773502691896257\n",
      "  (821, 2835)\t0.5773502691896257\n",
      "  (821, 167)\t0.5773502691896257\n",
      "  (822, 117)\t0.5463374026179089\n",
      "  (822, 79)\t0.5463374026179089\n",
      "  (822, 134)\t0.44890471427767037\n",
      "  (822, 1398)\t0.44890471427767037\n",
      "  (824, 1526)\t0.7196749209503762\n",
      "  (824, 994)\t0.694311175306195\n",
      "  (825, 2823)\t0.7428039849736764\n",
      "  (825, 1827)\t0.6695089543144485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<826x2915 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 9534 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "bag_of_word = TfidfVectorizer()\n",
    "word_cc = bag_of_word.fit_transform(documents)\n",
    " \n",
    "print (word_cc)\n",
    "word_cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `transform` method returns a sparse matrix. A sparse matrix is a more efficient manner of storing a matrix. If a matrix has mostly zero entries, it is better to just store the non-zero entries and their occurrence, their row and column. Sparse matrices have the method `toarray()` that returns a full matrix **but** doing so may result in memory issues. Some key hyperparameters of the `CountVectorizer` are shown below:\n",
    "\n",
    "* `min_df`: only counts words that appear in a minimum number of documents.\n",
    "* `max_df`: only counts words that do not appear more than a maximum number of documents.\n",
    "* `max_features`: limits the number of generated features, based on the frequency.\n",
    "\n",
    "After fitting a `CountVectorizer` object, the following method and attribute help with determining which index belongs to which word.\n",
    "\n",
    "* `get_feature_names()`: Returns a list of words used as features. The index of the word corresponds to the column index.\n",
    "* `vocabulary_`: A dictionary mapping a word to its corresponding feature index.\n",
    "\n",
    "Let's use `vocabulary_` to determine how many times \"programming\" occurs in the documents for Python the programming language and python the animal. Do the results make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words.vocabulary_['coiling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words.get_feature_names()[537]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get word counts\n",
    "counts_animal = bag_of_words.transform(animal_sents)\n",
    "counts_language = bag_of_words.transform(language_sents)\n",
    "\n",
    "# index for \"programming\"\n",
    "ind_programming = bag_of_words.vocabulary_['programming']\n",
    "\n",
    "# total counts across all documents\n",
    "print(counts_animal.sum(axis=0)[0, ind_programming])\n",
    "print(counts_language.sum(axis=0)[0, ind_programming])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `HashingVectorizer` transformer\n",
    "\n",
    "The `CountVectorizer` requires that we hold the mapping of words to features in memory. In addition, document processing cannot be parallelized because each worker needs to have the same mapping of word to column index. `CountVectorizer` objects are said to have _state_, they retain information of previous interactions and usage. A trick to improve the `CountVectorizer` is to use a hash function to convert the words into numbers. A hash function is a function that converts an input into a _deterministic_ value. In our context, we will use a hash function to convert a word into a number. The resulting number determines which feature column the word is mapped to. Python has a built-in hash function, seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-338443684736875854\n",
      "7190067919109105454\n",
      "-3168728522081972799\n",
      "-338443684736875854\n"
     ]
    }
   ],
   "source": [
    "print(hash(\"hi!\"))\n",
    "print(hash(\"python\"))\n",
    "print(hash(\"Pyton\"))\n",
    "print(hash(\"hi!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the function returns different values for different words. Also notice, the hash values of \"apple\" and \"apples\" are significantly different. Ideally no two inputs result in the same hash value, but this is impossible to avoid; when different inputs generate the same hash, it is referred to as a \"hash collision\".\n",
    "\n",
    "The `HashingVectorizer` class is similar to the `CountVectorizer` but it uses a hash function to render it *stateless*. The stateless nature of `HashingVectorizer` objects allows it to parallelize the counting process. There are two main disadvantages of `HashingVectorizer`:\n",
    "\n",
    "* Hash collisions are possible but in practice are often inconsequential.\n",
    "* Because the transformer is stateless, there is no mapping between word to feature index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<826x1048576 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 9534 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "hashing_bag_of_words = HashingVectorizer(norm=None) # by default, it normalizes the vectors\n",
    "hashing_bag_of_words.fit(documents)\n",
    "hashing_bag_of_words.transform(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how the feature matrix has over a million columns? This is in contrast from the result of the count vectorizer. The discrepancy is from the `HashingVectorizer` using, by default, $2^{20}=1048576$ different hash values to construct the count matrix. A vast majority of those indices will have no counts across all documents, and since we represent our feature matrix using a sparse matrix, we pay no cost for empty features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting time for CountVectorizer: 0.04991340637207031\n",
      "Fitting time for HashingVectorizer: 0.036817073822021484\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t_0 = time.time()\n",
    "CountVectorizer().fit_transform(documents)\n",
    "t_elapsed = time.time() - t_0\n",
    "print(\"Fitting time for CountVectorizer: {}\".format(t_elapsed))\n",
    "\n",
    "t_0 = time.time()\n",
    "HashingVectorizer(norm=None).fit_transform(documents)\n",
    "t_elapsed = time.time() - t_0\n",
    "print(\"Fitting time for HashingVectorizer: {}\".format(t_elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term frequency-inverse document frequency\n",
    "\n",
    "Both the `CountVectorizer` and `HashingVectorizer` creates a feature matrix of raw counts. Using raw counts has two problems, documents vary widely in length and the counts will be large for common words such as \"the\" and \"is\". We need to use a weighting scheme that considers the aforementioned attributes. The term frequency-inverse document frequency, **tf-idf** for short, is a popular weighting scheme to improve the simple count based data from the bag of words model. It is the product of two values, the term frequency and the inverse document frequency. There are several variants but the most popular is defined below.\n",
    "\n",
    "* **Term Frequency:**\n",
    "$$ \\mathrm{tf}(t, d) = \\frac{\\mathrm{counts}(t, d)}{\\sqrt{\\sum_{t \\in d} \\mathrm{counts}(t, d)^2}}, $$\n",
    "    where $\\mathrm{counts}(t, d)$ is the raw count of term $t$ in document $d$ and $t \\in d$ are the terms in document $d$. The normalization results in a vector of unit length.\n",
    "\n",
    "* **Inverse Document Frequency:**\n",
    "$$ \\mathrm{idf}(t, D) = \\ln\\left(\\frac{\\text{number of documents in corpus } D}{1 + \\text{number of documents with term } t}\\right). $$\n",
    "    Every counted term $t$ in the corpus will have its own idf weight. The $1+$ in the denominator is to ensure no division by zero if a term does not appear in the corpus. The idf weight is simply the log of the inverse of a term's document frequency.\n",
    "    \n",
    "With both $\\mathrm{tf}(t, d)$ and $\\mathrm{idf}(t, D)$ calculated, the tf-idf weight is\n",
    "\n",
    "$$ \\mathrm{tfidf}(t, d, D) = \\mathrm{tf}(t, d) \\mathrm{idf}(t, D).$$\n",
    "\n",
    "With the idf weighting, words that are very common throughout the documents get weighted down. The reverse is true; the count of rare words get weighted up. With the tf-idf weighting scheme, a machine learning model will have an easier time to learn patterns to properly predict labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to apply the tf-idf weighting in `scikit-learn`, differing in what input they work on. `TfidfVectorizer` works on an array of documents (e.g., list of sentences) while the `TfidfTransformer` works on a count matrix, like the outputs of `HashingVectorizer` and `CountVectorizer`. `TfidfVectorizer` encapsulates the `CountVectorizer` and `TfidfTransformer` into one class. Since we have already calculated the word counts, we will demonstrate the `TfidfTransformer`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2669)\t0.13535498654153616\n",
      "  (0, 2630)\t0.11494981478971213\n",
      "  (0, 2455)\t0.3145642370396516\n",
      "  (0, 2443)\t0.3480564896372768\n",
      "  (0, 2442)\t0.36077127313341345\n",
      "  (0, 2214)\t0.3288842051777745\n",
      "  (0, 2212)\t0.23717797173946778\n",
      "  (0, 2081)\t0.2467069894290522\n",
      "  (0, 1745)\t0.3212755481623284\n",
      "  (0, 1582)\t0.3480564896372768\n",
      "  (0, 1397)\t0.15387668026180157\n",
      "  (0, 280)\t0.36077127313341345\n",
      "  (0, 229)\t0.12139969348210765\n",
      "  (1, 2879)\t0.26476675828750795\n",
      "  (1, 2854)\t0.2578795385261705\n",
      "  (1, 2630)\t0.18026530143408043\n",
      "  (1, 2417)\t0.1834895041453948\n",
      "  (1, 2138)\t0.27291261032186964\n",
      "  (1, 1835)\t0.16497322832077918\n",
      "  (1, 1822)\t0.11062652077025796\n",
      "  (1, 1551)\t0.27291261032186964\n",
      "  (1, 1530)\t0.2957355283559717\n",
      "  (1, 1529)\t0.23379798821904416\n",
      "  (1, 1495)\t0.2578795385261705\n",
      "  (1, 1417)\t0.2957355283559717\n",
      "  :\t:\n",
      "  (815, 812)\t0.7715645872738824\n",
      "  (816, 255)\t1.0\n",
      "  (817, 1398)\t0.44890471427767037\n",
      "  (817, 134)\t0.44890471427767037\n",
      "  (817, 94)\t0.5463374026179089\n",
      "  (817, 66)\t0.5463374026179089\n",
      "  (819, 2558)\t0.641333453333285\n",
      "  (819, 1607)\t0.5576784284270643\n",
      "  (819, 51)\t0.5269593647547438\n",
      "  (820, 2081)\t0.20248018607736457\n",
      "  (820, 2036)\t0.4101896885579848\n",
      "  (820, 1303)\t0.2277107282998262\n",
      "  (820, 862)\t0.554269095014101\n",
      "  (820, 73)\t0.6570234304621043\n",
      "  (821, 2835)\t0.5773502691896257\n",
      "  (821, 2030)\t0.5773502691896257\n",
      "  (821, 167)\t0.5773502691896257\n",
      "  (822, 1398)\t0.44890471427767037\n",
      "  (822, 134)\t0.44890471427767037\n",
      "  (822, 117)\t0.5463374026179089\n",
      "  (822, 79)\t0.5463374026179089\n",
      "  (824, 1526)\t0.7196749209503762\n",
      "  (824, 994)\t0.694311175306195\n",
      "  (825, 2823)\t0.7428039849736764\n",
      "  (825, 1827)\t0.6695089543144485\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "tfidf_weights = tfidf.fit_transform(word_counts)\n",
    "print(tfidf_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We no longer have raw counts in our feature matrix. Let's use the `idf_` attribute of the fitted tf-idf transformer to inspect the top idf weights and their corresponding terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.024657514463746 zope\n",
      "7.024657514463746 gripping\n",
      "7.024657514463746 guard\n",
      "7.024657514463746 grumpy\n",
      "7.024657514463746 grows\n",
      "7.024657514463746 grown\n",
      "7.024657514463746 growing\n",
      "7.024657514463746 groovy\n",
      "7.024657514463746 gripped\n",
      "7.024657514463746 healthy\n",
      "7.024657514463746 greatest\n",
      "7.024657514463746 greater\n",
      "7.024657514463746 grass\n",
      "7.024657514463746 graphviz\n",
      "7.024657514463746 graphical\n",
      "7.024657514463746 grams\n",
      "7.024657514463746 guide\n",
      "7.024657514463746 guinea\n",
      "7.024657514463746 gutted\n"
     ]
    }
   ],
   "source": [
    "top_idf_indices = tfidf.idf_.argsort()[:-20:-1]\n",
    "ind_to_word = bag_of_words.get_feature_names()\n",
    "\n",
    "for ind in top_idf_indices:\n",
    "    print(tfidf.idf_[ind], ind_to_word[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using tf-idf weighting renders the process as _stateful_; to apply the idf weight, we need to know the frequency of each word across all documents. While we may initially use `HasingVectorizer` to have a stateless transformer, coupling it with `TfidfTransformer` will create a stateful process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving signal\n",
    "\n",
    "So far, we have discussed how using tf-idf rather than raw counts will improve the performance of our machine learning model. There are several other approaches that can boost performance; we will discuss techniques that improve the signal in our data set. Note, the following techniques may marginally increase model performance. It may be best to create a baseline model and measure the increased performance with the new model additions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words\n",
    "\n",
    "Words such as \"the\", \"a\", and \"or\" are so common throughout our corpus that they do not contribute any signal to our data set. Further, omitting these words will reduce our already high dimensional data set. It is best to not have these words as features and not be counted in the analysis. The set of words that will not factor into our analysis are called **stop words**.\n",
    "\n",
    "spaCy provides a `set` of around 300 commonly used English words. When using stop words, it is best to examine the entries in case there are certain words you want to be included or not included. Since the words are provided as a Python `set`, we can use methods available to `set` objects to modify entries of the `set` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'set'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\"'d\",\n",
       " \"'ll\",\n",
       " \"'m\",\n",
       " \"'re\",\n",
       " \"'s\",\n",
       " \"'ve\",\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'across',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amount',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anyhow',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'are',\n",
       " 'around',\n",
       " 'as',\n",
       " 'at',\n",
       " 'back',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'both',\n",
       " 'bottom',\n",
       " 'but',\n",
       " 'by',\n",
       " 'ca',\n",
       " 'call',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'could',\n",
       " 'did',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doing',\n",
       " 'done',\n",
       " 'down',\n",
       " 'due',\n",
       " 'during',\n",
       " 'each',\n",
       " 'eight',\n",
       " 'either',\n",
       " 'eleven',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'empty',\n",
       " 'enough',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'except',\n",
       " 'few',\n",
       " 'fifteen',\n",
       " 'fifty',\n",
       " 'first',\n",
       " 'five',\n",
       " 'for',\n",
       " 'former',\n",
       " 'formerly',\n",
       " 'forty',\n",
       " 'four',\n",
       " 'from',\n",
       " 'front',\n",
       " 'full',\n",
       " 'further',\n",
       " 'get',\n",
       " 'give',\n",
       " 'go',\n",
       " 'had',\n",
       " 'has',\n",
       " 'have',\n",
       " 'he',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'however',\n",
       " 'hundred',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'indeed',\n",
       " 'into',\n",
       " 'is',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'keep',\n",
       " 'last',\n",
       " 'latter',\n",
       " 'latterly',\n",
       " 'least',\n",
       " 'less',\n",
       " 'made',\n",
       " 'make',\n",
       " 'many',\n",
       " 'may',\n",
       " 'me',\n",
       " 'meanwhile',\n",
       " 'might',\n",
       " 'mine',\n",
       " 'more',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'move',\n",
       " 'much',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " \"n't\",\n",
       " 'name',\n",
       " 'namely',\n",
       " 'neither',\n",
       " 'never',\n",
       " 'nevertheless',\n",
       " 'next',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'none',\n",
       " 'noone',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'n‘t',\n",
       " 'n’t',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'or',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 'part',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'please',\n",
       " 'put',\n",
       " 'python',\n",
       " 'quite',\n",
       " 'rather',\n",
       " 're',\n",
       " 'really',\n",
       " 'regarding',\n",
       " 'same',\n",
       " 'say',\n",
       " 'see',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'serious',\n",
       " 'several',\n",
       " 'she',\n",
       " 'should',\n",
       " 'show',\n",
       " 'side',\n",
       " 'since',\n",
       " 'six',\n",
       " 'sixty',\n",
       " 'so',\n",
       " 'some',\n",
       " 'somehow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sometime',\n",
       " 'sometimes',\n",
       " 'somewhere',\n",
       " 'still',\n",
       " 'such',\n",
       " 'take',\n",
       " 'ten',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'there',\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " 'therefore',\n",
       " 'therein',\n",
       " 'thereupon',\n",
       " 'these',\n",
       " 'they',\n",
       " 'third',\n",
       " 'this',\n",
       " 'those',\n",
       " 'though',\n",
       " 'three',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'to',\n",
       " 'together',\n",
       " 'too',\n",
       " 'top',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'twelve',\n",
       " 'twenty',\n",
       " 'two',\n",
       " 'under',\n",
       " 'unless',\n",
       " 'until',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'used',\n",
       " 'using',\n",
       " 'various',\n",
       " 'very',\n",
       " 'via',\n",
       " 'was',\n",
       " 'we',\n",
       " 'well',\n",
       " 'were',\n",
       " 'what',\n",
       " 'whatever',\n",
       " 'when',\n",
       " 'whence',\n",
       " 'whenever',\n",
       " 'where',\n",
       " 'whereafter',\n",
       " 'whereas',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'whither',\n",
       " 'who',\n",
       " 'whoever',\n",
       " 'whole',\n",
       " 'whom',\n",
       " 'whose',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without',\n",
       " 'would',\n",
       " 'yet',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " '‘d',\n",
       " '‘ll',\n",
       " '‘m',\n",
       " '‘re',\n",
       " '‘s',\n",
       " '‘ve',\n",
       " '’d',\n",
       " '’ll',\n",
       " '’m',\n",
       " '’re',\n",
       " '’s',\n",
       " '’ve'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.en import STOP_WORDS\n",
    "\n",
    "print(type(STOP_WORDS))\n",
    "STOP_WORDS_python = STOP_WORDS.union({\"python\"})\n",
    "STOP_WORDS_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming and lemmatization\n",
    "\n",
    "In our current analysis, words like \"python\" and \"pythons\" will be counted as separate words. We understand that they represent the same concept and want them to be treated as the same word. The same applies to other words like \"run\", \"runs\", \"ran\", and \"running\", they all represent the same meaning. **Stemming** is the process of reducing a word to its stem. Note, the stemming process is not 100% effective and sometimes the resulting stem is not an actual word. For example, the popular Porter stemming algorithm applied to \"argues\" and \"arguing\" returns `\"argu\"`.\n",
    "\n",
    "**Lemmatization** is the process of reducing a word to its lemma, or the dictionary form of the word. It is a more sophisticated process than stemming as it considers context and part of speech. Further, the resulting lemma is an actual word. spaCy does not have a stemming algorithm but does offer lemmatization. Each word analyzed by spaCy has the attribute `lemma_` which returns the lemma of the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'run', 'run', 'run']\n",
      "['buy', 'buy', 'buying', 'buy']\n",
      "['see', 'see', 'see', 'see']\n"
     ]
    }
   ],
   "source": [
    "print([word.lemma_ for word in nlp('run runs ran running')])\n",
    "print([word.lemma_ for word in nlp('buy buys buying bought')])\n",
    "print([word.lemma_ for word in nlp('see saw seen seeing')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: As of version 2.0.16 of spaCy, there is the bug with the English lemmatization and will fail in instances it should not. However, the bug has been fixed and a patch will be included in a future update, version 2.1.x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply lemmatization in `scikit-learn`, you need to pass a function to the keyword `tokenizer` of whatever text vectorizer you are deploying. See the example below were we apply lemmatization for a `TfidfVectorizer` transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def lemmatizer(text):\n",
    "    return [word.lemma_ for word in nlp(text)]\n",
    "\n",
    "# we need to generate the lemmas of the stop words\n",
    "# stop_words_str = \" \".join(STOP_WORDS) # nlp function needs a string\n",
    "# stop_words_lemma = set(word.lemma_ for word in nlp(stop_words_str))\n",
    "\n",
    "# tfidf_lemma = TfidfVectorizer(max_features=100, \n",
    "#                               stop_words=stop_words_lemma.union({\"python\"}),\n",
    "#                               tokenizer=lemmatizer)\n",
    "\n",
    "# tfidf_lemma.fit(documents)\n",
    "# print(tfidf_lemma.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization and n-grams\n",
    "\n",
    "Tokenization refers to dividing up a document into pieces to be counted. In our analysis so far, we are only counting words. However, it may be useful to count a sequence of words such as \"natural environment\" and \"virtual environment\". Counting these **bigrams** for our word usage analyzer may boost performance. More generally, an n-gram refers to the n sequence of words. In `scikit-learn`, n-grams can be included by setting `ngram_range=(min_n, max_n)` for the vectorizer, where `min_n` and `max_n` are the lower and upper bound of the range of n-grams to include. For example, `ngram_range=(1, 2)` will include words and bigrams while `ngram_range=(2, 2)` will only count bigrams. Let's see what are the most frequent bigrams in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kagum\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['23 ft',\n",
       " 'ball pythons',\n",
       " 'design philosophy',\n",
       " 'floating point',\n",
       " 'ft 10',\n",
       " 'ft length',\n",
       " 'ft long',\n",
       " 'isbn 978',\n",
       " 'lb oz',\n",
       " 'new features',\n",
       " 'object oriented',\n",
       " 'oriented programming',\n",
       " 'programming language',\n",
       " 'programming languages',\n",
       " 'reticulated pythons',\n",
       " 'scripting language',\n",
       " 'spam eggs',\n",
       " 'standard library',\n",
       " 'van rossum',\n",
       " 'year old']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_counter=CountVectorizer(max_features=20, ngram_range=(2,3), stop_words=STOP_WORDS.union({\"python\"}))\n",
    "bigram_counter.fit(documents)\n",
    "\n",
    "bigram_counter.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "* Is using stop words more important when using `CountVectorizer`/`HashingVectorizer` or when using the `TfidfVectorizer`? \n",
    "\n",
    "\n",
    "Stop words are important coz they prevent more features\n",
    "* Is it practical to use a large n-gram range, for example, count 3-grams?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document similarity\n",
    "\n",
    "After we have transformed our corpus into a matrix, we can interpret our data set as representing a set of vectors in a $p$-dimensional space, where each document is its own vector. One common analysis is to find similar documents. The cosine similarity is a metric that measure how well aligned in space are two vectors, equal to the cosine of the angle in between the two vectors. If the vectors are perfectly aligned, they point in the same direction, the angle they form is 0 and the similarity score is 1. If the vectors are orthogonal, forming an angle of 90 degrees, the similarity metric is 0. Mathematically, the cosine similarity metric is equal to the dot product of two vectors, normalized,\n",
    "\n",
    "$$ \\frac{v_1 \\cdot v_2}{\\|v_1 \\|\\|v_2 \\|}, $$\n",
    "\n",
    "where $v_1$ and $v_2$ are two document vectors and $\\| v_1 \\|$ and $\\| v_2 \\|$ are their lengths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word usage classifier\n",
    "\n",
    "Let's build a word usage classifier with all the techniques we have seen. The model will include:\n",
    "\n",
    "* tf-idf weighting\n",
    "* stop words\n",
    "* words and bigrams\n",
    "* lemmatization\n",
    "\n",
    "Applying the above techniques should result in a data set with enough signal that a machine learning model can learn from. For this exercise, we will use the naive Bayes model; a probabilistic model that calculates conditional probabilities using Bayes theorem. The term naive is applied because it assumes the features are conditionally independent from each other. You can think of a naive Bayes classifier working by determining what class should a document be assigned based upon the frequencies of words in the different classes in the training set. Naive Bayes is often used as benchmark model for NLP as it is quick to train. More about the model in general can be found [here](https://en.wikipedia.org/wiki/Naive_Bayes_classifier) and details of the `scikit-learn` implementation is found [here](https://scikit-learn.org/stable/modules/naive_bayes.html). After training our model, we will see how well it performs for a chosen set of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9092009685230025\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# create data set and labels\n",
    "documents = animal_sents + language_sents\n",
    "labels = [\"animal\"]*len(animal_sents) + [\"language\"]*len(language_sents)\n",
    "\n",
    "# lemma of stop words\n",
    "stop_words_str = \" \".join(STOP_WORDS)\n",
    "stop_words_lemma = set(word.lemma_ for word in nlp(stop_words_str))\n",
    "\n",
    "# create and train pipeline\n",
    "tfidf = TfidfVectorizer(stop_words=stop_words_lemma, tokenizer=lemmatizer, ngram_range=(1, 2))\n",
    "pipe = Pipeline([('vectorizer', tfidf), ('classifier', MultinomialNB())])\n",
    "pipe.fit(documents, labels)\n",
    "\n",
    "print(\"Training accuracy: {}\".format(pipe.score(documents, labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_docs = [\"My Python program is only 100 bytes long.\",\n",
    "             \"A python's bite is not venomous but still hurts.\",\n",
    "             \"I can't find the error in the python code.\",\n",
    "             \"Where is my pet python; I can't find her!\",\n",
    "             \"I use for and while loops when writing Python.\",\n",
    "             \"The python will loop and wrap itself onto me.\",\n",
    "             \"I use snake case for naming my variables.\",\n",
    "             \"My python has grown to over 10 ft long!\",\n",
    "             \"I use virtual environments to manage package versions.\",\n",
    "             \"Pythons are the largest snakes in the environment.\"]\n",
    "\n",
    "class_labels = [\"animal\", \"language\"]\n",
    "y_proba = pipe.predict_proba(test_docs)\n",
    "predicted_indices = (y_proba[:, 1] > 0.5).astype(int)\n",
    "\n",
    "for i, index in enumerate(predicted_indices):\n",
    "    print(test_docs[i], \"--> {} at {:g}%\".format(class_labels[index], 100*y_proba[i, index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<property at 0x18dc963f860>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultinomialNB.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<enumerate at 0x18dc9374200>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enumerate((y_proba[:, 1]>.5).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_proba[:,1]>0.5).astype (int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Encapsulate the entire process of gathering a corpus, constructing, and training a model into a function. Afterwards, deploy the model to other sets of homonyms.\n",
    "1. Measure the model's improvements by stripping out things such as the use of stop words and lemmatization. Perhaps you can incorporate model additions as parameters to the previously mentioned function. What model additions increases the performance the most?\n",
    "1. Consider another source of data and see how well the model performs with the new corpus.\n",
    "1. Naive Bayes classifier calculates conditional probabilities from the training set. In other words, it determines values like $P(\\text{snake | }Y = \\text{animal})$, the probability a document has the word \"snake\" given if the document belongs to those of python the animal. These values are stored in `coef_` attribute of a trained naive Bayes model. Can you use these coefficients to determine the most discriminative features? In other words, what terms when found in a document really help classify the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "MultinomialNB?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOLUTION 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus (words):\n",
    "    corpus = [] #list of sentences\n",
    "    labels = []  #list of labels\n",
    "    \n",
    "    for k, v in words.items():\n",
    "        docs = pages_to_sentences(*v)  #list of sentences or documents from wikipedia pages \n",
    "        corpus += docs\n",
    "        labels += [k] * len(docs)\n",
    "        \n",
    "    return corpus, labels\n",
    "\n",
    "words = {'greek':['Amazons'],\n",
    "        'rainforest':['Amazon_rainforest'],\n",
    "        'company': ['Amazon_(company)']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, labels = get_corpus(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greek ---> ['Amazons']\n",
      "rainforest ---> ['Amazon_rainforest']\n",
      "company ---> ['Amazon_(company)']\n"
     ]
    }
   ],
   "source": [
    "for k, v in words.items():\n",
    "    print (k,'--->', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1157"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOLUTION 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtrest, ytrain, ytest = train_test_split(corpus, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "TfidfVectorizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "parama_grid = {\"vectorizer__ngram_range\":[(1,1), (1,2)],\n",
    "              'vectorizer__tokenizer': [None, lemmatizer]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                                       ('clf', MultinomialNB())]),\n",
       "             param_grid={'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'vectorizer__tokenizer': [None,\n",
       "                                                   <function lemmatizer at 0x0000018DC9303CA0>]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipe, param_grid=parama_grid, verbose=1, cv=5)\n",
    "grid_search.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7107696827262047"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.03930826, 5.9766849 , 0.06104579, 5.78112817]),\n",
       " 'std_fit_time': array([0.01572457, 0.21210513, 0.00246975, 0.06842055]),\n",
       " 'mean_score_time': array([0.0059762 , 1.44135571, 0.00836811, 1.4491365 ]),\n",
       " 'std_score_time': array([0.00140542, 0.03941353, 0.00048654, 0.03870043]),\n",
       " 'param_vectorizer__ngram_range': masked_array(data=[(1, 1), (1, 1), (1, 2), (1, 2)],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_vectorizer__tokenizer': masked_array(data=[None, <function lemmatizer at 0x0000018DC9303CA0>,\n",
       "                    None, <function lemmatizer at 0x0000018DC9303CA0>],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': None},\n",
       "  {'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__tokenizer': <function __main__.lemmatizer(text)>},\n",
       "  {'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': None},\n",
       "  {'vectorizer__ngram_range': (1, 2),\n",
       "   'vectorizer__tokenizer': <function __main__.lemmatizer(text)>}],\n",
       " 'split0_test_score': array([0.6972973 , 0.69189189, 0.65405405, 0.64324324]),\n",
       " 'split1_test_score': array([0.68648649, 0.72432432, 0.67567568, 0.67027027]),\n",
       " 'split2_test_score': array([0.68108108, 0.67567568, 0.67027027, 0.64864865]),\n",
       " 'split3_test_score': array([0.76086957, 0.75543478, 0.74456522, 0.71195652]),\n",
       " 'split4_test_score': array([0.72282609, 0.70652174, 0.69565217, 0.69021739]),\n",
       " 'mean_test_score': array([0.7097121 , 0.71076968, 0.68804348, 0.67286722]),\n",
       " 'std_test_score': array([0.02933378, 0.02751256, 0.03123053, 0.02568994]),\n",
       " 'rank_test_score': array([2, 1, 3, 4])}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = grid_search.cv_results_\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': None},\n",
       " {'vectorizer__ngram_range': (1, 1),\n",
       "  'vectorizer__tokenizer': <function __main__.lemmatizer(text)>},\n",
       " {'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': None},\n",
       " {'vectorizer__ngram_range': (1, 2),\n",
       "  'vectorizer__tokenizer': <function __main__.lemmatizer(text)>}]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7097121 , 0.71076968, 0.68804348, 0.67286722])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praw\n",
      "  Downloading praw-7.3.0-py3-none-any.whl (165 kB)\n",
      "Collecting prawcore<3,>=2.1\n",
      "  Downloading prawcore-2.2.0-py3-none-any.whl (15 kB)\n",
      "Collecting websocket-client>=0.54.0\n",
      "  Downloading websocket_client-1.1.0-py2.py3-none-any.whl (68 kB)\n",
      "Collecting update-checker>=0.18\n",
      "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\users\\kagum\\anaconda3\\lib\\site-packages (from prawcore<3,>=2.1->praw) (2.25.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kagum\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kagum\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\kagum\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\kagum\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (4.0.0)\n",
      "Installing collected packages: websocket-client, update-checker, prawcore, praw\n",
      "Successfully installed praw-7.3.0 prawcore-2.2.0 update-checker-0.18.0 websocket-client-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid_search.best_estimator_.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_.predict_log_proba?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xtest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-6a7ca3fc023b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'xtest' is not defined"
     ]
    }
   ],
   "source": [
    "model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright &copy; 2018 The Data Incubator.  All rights reserved.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nbclean": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
