{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "matplotlib.rcParams['savefig.dpi'] = 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics for supervised machine learning\n",
    "\n",
    "The general problem supervised machine learning seeks to solve is to map a measurement of several variables to a target value or class. For example, we might use supervised machine learning to transcribe spoken language to text, predict home values based on neighborhood amenities, or detect fraudulent transactions. In order to assess whether our model is succeeding, we need to formally define what success is for the given task. In this notebook, we will explore several common **metrics** for model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematics of supervised learning\n",
    "\n",
    "For most machine-learning problems, our model receives a vector of **features**, $X$, and maps it to some predicted label, $y$. In order to train our model, we will need many **observations** (i.e. measurements) and their associated labels. We can assemble these observations into a matrix.\n",
    "\n",
    "$$ f(X_{ij}) \\approx y_i $$\n",
    "\n",
    "We'll use the California housing data set as an example. The California housing data set has measurements of average house age, average number of rooms, location, and other qualities for various census blocks of California."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget http://dataincubator-wqu.s3.amazonaws.com/caldata/cal_housing.pkz -nc -P ~/scikit_learn_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "California housing dataset.\n",
      "\n",
      "The original database is available from StatLib\n",
      "\n",
      "    http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The data contains 20,640 observations on 9 variables.\n",
      "\n",
      "This dataset contains the average house value as target variable\n",
      "and the following input variables (features): average income,\n",
      "housing average age, average rooms, average bedrooms, population,\n",
      "average occupation, latitude, and longitude in that order.\n",
      "\n",
      "References\n",
      "----------\n",
      "\n",
      "Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "Statistics and Probability Letters, 33 (1997) 291-297.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  \n",
       "0    -122.23  \n",
       "1    -122.22  \n",
       "2    -122.24  \n",
       "3    -122.25  \n",
       "4    -122.25  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "cali_data = fetch_california_housing()\n",
    "\n",
    "print(cali_data.DESCR)\n",
    "\n",
    "cali_df = pd.DataFrame(cali_data.data, columns=cali_data.feature_names)\n",
    "cali_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above dataframe, each column is a feature (i.e. a variable) and each row is an observation (i.e. a measurement). Said another way, things like median income and average number of rooms are features, while each census block for which we have a measurement of the features is an observation. We also have a vector of target labels, which is the median home value for each neighborhood. Altogether we have 9 features and 20640 observations with labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "print(cali_data.data.shape)\n",
    "print(cali_data.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we design a model to predict real number values (e.g. home price), our model is a **regression model**. Alternatively, we could design a model to predict categorical labels, such as \"expensive neighborhood\" and \"inexpensive neighborhood\". This would be a **classification model**. Most supervised machine learning tasks fall into the category of **regression** or **classification**. In either case we have to define a metric that quantifies what we mean by $\\approx$ in the equation above.\n",
    "\n",
    "We use our metric to define a **cost function** (let's call it $C$). To carry out gradient descent, we numerically evaluate the derivative of $C$ with respect to our model parameters.\n",
    "\n",
    "$$ \\frac{dC}{df} = \\nabla_f C = \\left(\\frac{\\partial C}{\\partial \\Theta_1}, \\frac{\\partial C}{\\partial \\Theta_2}, ...\\right) $$\n",
    "\n",
    "Often the cost function, $C$, will be the same as our metric, but sometimes it may have additional terms, which we will explore later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics for regression tasks\n",
    "\n",
    "In the [notebook on linear regression](ML_LinearRegression.ipynb) we introduced mean squared error (MSE) as a metric for how our trend line was performing. This lead us to define a cost function, a scalar function that depends on our model parameters. We minimized the cost function using gradient descent. Depending on what problem we are trying to solve and what we want to optimize, we may choose different metrics.\n",
    "\n",
    "**Mean squared error** (MSE) is one of the most common metrics for regression:\n",
    "\n",
    "$$ \\frac{1}{n}\\sum_i\\left[f(X_i) - y_i\\right]^2 $$\n",
    "\n",
    "We squared the error terms ($f(X_i) - y_i$) because we didn't care whether they were positive or negative. We could have also addressed this concern by taking the absolute value, which would lead to the **mean absolute error** (MAE)\n",
    "\n",
    "$$ \\frac{1}{n}\\sum_i|f(X_i) - y_i| $$\n",
    "\n",
    "When we minimize the MAE by adjusting our model parameters, our model will be less strongly affected by outliers than if we used the MSE. This is because the error terms from outliers (which will generally be large) enter into the MAE a linear terms rather than being squared.\n",
    "\n",
    "Another common metric for regression is $R^2$, also known as the **coefficient of determination**. The $R^2$ quantifies how our model's MSE compares to a naive model in which we always predict the mean $y$ value, $\\bar{y}$.\n",
    "\n",
    "$$ 1 - \\frac{\\sum_i \\left[f(X_i) - y_i\\right]^2}{\\sum_i\\left(\\bar{y} - y_i\\right)^2} $$\n",
    "\n",
    "If our $R^2 < 0$ we know our model is very bad, because the MSE is larger than than the MSE of the mean model.\n",
    "\n",
    "One important consideration when choosing a metric is how they scale with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.379185\n",
      "MAE: 0.541616\n",
      "R^2: 0.596714\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "y = np.random.randn(10)\n",
    "y_pred = y + .5 * np.random.randn(10)\n",
    "\n",
    "print('MSE: %f' % metrics.mean_squared_error(y, y_pred))\n",
    "print('MAE: %f' % metrics.mean_absolute_error(y, y_pred))\n",
    "print('R^2: %f' % metrics.r2_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.516738\n",
      "MAE: 1.083231\n",
      "R^2: 0.596714\n"
     ]
    }
   ],
   "source": [
    "# rescale y\n",
    "\n",
    "y = 2 * y\n",
    "y_pred = 2 * y_pred\n",
    "\n",
    "print('MSE: %f' % metrics.mean_squared_error(y, y_pred))\n",
    "print('MAE: %f' % metrics.mean_absolute_error(y, y_pred))\n",
    "print('R^2: %f' % metrics.r2_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics for classification tasks\n",
    "\n",
    "The metrics for regression rely on calculating an error term (i.e. the difference between our prediction and the ground truth). We can't do this for a classification task, so we will need to define entirely different metrics for classification. Let's start with the possible outcomes when we make a prediction.\n",
    "\n",
    "|                        | Actual positive | Actual negative |\n",
    "|------------------------|:---------------:|:---------------:|\n",
    "| **Predicted positive** |  True positive  |  False positive |\n",
    "| **Predicted negative** |  False negative |  True negative  |\n",
    "\n",
    "We have four possible outcomes we can use build our metric. We'll consider only three possibilities (though many more metrics have been defined).\n",
    "\n",
    "**Accuracy** is the most intuitive: it is the amount of proportion of true positives and negatives. We add up the true positives and true negatives and divide by the total number of predictions.\n",
    "\n",
    "Accuracy suffers from tasks in which there is class imbalance. For instance, in fraud detection, actual positives are very rare. Therefore, we could get high accuracy by simply always predicting negative. If only 0.1% of all observations are actually positive, then a model that always predicts negative gets 99.9% accuracy, even though this is clearly a bad model for detecting fraud.\n",
    "\n",
    "This example illustrates that we often care about one class more than another. For instance, if we think a transaction is fraudulent, we might waste some resources investigating it, but missing a case of fraud could cost much more. In this case we might want most to avoid false negatives.\n",
    "\n",
    "**Recall** is the count of true positives divided by the count of _actual positives_. Recall will be close to 1 as long as the count of false negatives is low, even if there are not many actual positives.\n",
    "\n",
    "On the other hand, if a fraud case goes to trial, we do not want to punish a defendant unfairly. In that case it's important to avoid false positives. **Precision** is the count of true positives divided by the count of positive predictions. As long as the count of false positives is low, precision will be close to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.875000\n",
      "Recall: 1.000000\n",
      "Precision: 0.800000\n"
     ]
    }
   ],
   "source": [
    "y = [0, 0, 1, 0, 1, 1, 0, 1]\n",
    "y_pred = [0, 1, 1, 0, 1, 1, 0, 1]\n",
    "\n",
    "print('Accuracy: %f' % metrics.accuracy_score(y, y_pred))\n",
    "print('Recall: %f' % metrics.recall_score(y, y_pred))\n",
    "print('Precision: %f' % metrics.precision_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision-recall tradeoff\n",
    "\n",
    "There is a tradeoff between precision and recall as we adjust our model, exchanging positive predictions for negative predictions.\n",
    "\n",
    "Often our classification model won't predict whether an observation is in one class or another, but rather will predict the _probability_ of the observation being in one class or the other. We choose a threshold probability, above which we will predict the observation is in the positive class, and below which we'll predict negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_pred = np.linspace(0, 1, 1000)\n",
    "y = np.random.binomial(1, p_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a03fa8db8ed4930aab7572ff3e6db12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='threshold', max=1.0), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "def plot_threshold(threshold=0.5):\n",
    "    true_pos = (p_pred > threshold) & (y == 1)\n",
    "    true_neg = (p_pred < threshold) & (y == 0)\n",
    "    false_pos = (p_pred > threshold) & (y == 0)\n",
    "    false_neg = (p_pred < threshold) & (y == 1)\n",
    "\n",
    "    plt.plot(p_pred[true_pos], y[true_pos], '.', label='True positive')\n",
    "    plt.plot(p_pred[false_pos], y[false_pos], '.', label='False positive')\n",
    "    plt.plot(p_pred[true_neg], y[true_neg], '.', label='True negative')\n",
    "    plt.plot(p_pred[false_neg], y[false_neg], '.', label='False negative')\n",
    "\n",
    "    plt.axvline(threshold)\n",
    "    plt.ylim(-0.25, 1.25)\n",
    "    plt.legend()\n",
    "\n",
    "    precision = 1\n",
    "    if (p_pred > threshold).sum() > 0:\n",
    "        precision = float(true_pos.sum()) / (true_pos.sum() + false_pos.sum())\n",
    "    recall = float(true_pos.sum()) / (true_pos.sum() + false_neg.sum())\n",
    "\n",
    "    plt.title('Precision: %0.2f | Recall: %0.2f' % (precision, recall))\n",
    "\n",
    "interact(plot_threshold, threshold=(0, 1, 0.1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAETCAYAAAA/NdFSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VOXZ//HPTBayL4QAYYcAt8guCGJxoe5WK7YuVWvr1tba/lrro3XrYn1qa61a21pb9+fR2vrY1rUq7laQTZR9udh3kAAhCQSyTX5/nCEGJGFIcmYmme/79eLlnGXOue4kzjXnPue+7kB9fT0iIpJ4grEOQEREYkMJQEQkQSkBiIgkKCUAEZEEpQQgIpKglABERBJUcqwDkMTmnOsHrAIWNlodAH5vZk+00TnuBFaa2VPN7DMPONnMdrXFOY+Uc+59oC9QFl6VBHQCftlc3K0431rgAiALeNDMhrX1OST+KQFIPNhrZqP2LzjnegKLnHNzzGxBaw9uZj+LYJ9Rh9snCm4ys3/uX3DOjQU+dM69YGYVMYxLOiglAIk7ZrbJObcCGOycOwa4GsgEysxsknPuauA6vC7MHcD3zWyZcy4L+CPwBaAWeBG4HXgSWGRm9zrnfgGcD1SH33uFmW1xztUDhWa23Tn3U+CS8DGWh4+/NfwtfUb4+H2At4Fvm1lof+zOucHAdKCHmVU755KA9cCpZrb0CH8UA4A9QFX42OcCPwFSgUrgRjOb4ZxLBu4BzgnHPD3888kHHga6Ad2BdcBFZrbtCOOQDkr3ACTuOOcmAAOBWeFVQ/G6ZyY5504CvgmcYGaj8T74XgjvdyeQBgwBRuF9UJ/U6Li9geuBY81sLPAmMP6gc18JnBXeZwSwCPifRrsUAycDI8L7ndT4/Wa2HFgMfDm86nRgTYQf/r91zs1zzq1zzn2Kl6hOCSeSQcCvgLPD7f428LxzLhPvw34MMBIYBmQDFwNfA2aY2QS8ZFIJXB5BHJIgdAUg8SA93AcP3t/kduAyM9vgnANYYGbl4e1fwksO08PbAPKdc52BU4EbzKwOqCP84eycuyK83yZgPvCJc+514HUze+egWM4CnjSzPeHl3wO3O+dSw8uvhL/xlzvnVgKdD9Gex4ArgH8CVwKPRvhzuMnM/umcKwReAzaa2dzwttOAIuCdRu0OhX8WpwJPm9ne8PqL9+/gnDvBOXcDMAgvOexPqiJKABIXDrgHcAi7G71OwvuwuxnAORcEegCleN0fDcWtwt/4K/cvm1kofAUxFu9D83fOuSlm9uODjt+4QFYQ7/+TwP5YG22rb7S+sX8A9zvnhuAloSuaadvnmFmJc+5ivPsgM8zs+XBc75hZ4w/33sDmQ7S7Wzju64FxwBPAe0BKE/FKglIXkLQ3bwCXOOeKwsvXAvu/xb8NfNM5F3TOdcL7Bt64C2gkXpfOUjP7NfA74NiDjj8FuCrctQLwA+ADM6uKNEAz2wc8i9d19C8zq2z+HYc8xmrgLuD34VjeAU53zh0VbsvZwAIgHa/dlzrnOoUT4p/x7mGcATxgZk8D2/CuIpKONBbpuJQApF0xszeB3wBvOecWAJcCXzGzeuAXeDd35wNzgdfC3573v3c+8Bwwxzk3B7gKuOGgUzyO94E62zm3FDgGuKwFoT6K9+37sf0rnHNfds69dgTHuBfviuMnZrYEr9//WefcfOC/gS+b2W68G70fh/8tBLYAf8C7J3Jv+Of0MjANr8tIBICAykGLiCQmXQGIiCQoJQARkQSlBCAikqCUAEREElS7GQdQUlLR4rvV+fkZlJYe8ZN47ZranBjU5sTQmjYXFmY3OfYjIa4AkpMT79FntTkxqM2Jwa82J0QCEBGRz1MCEBFJUEoAIiIJSglARCRBKQGIiCQoJQARkQTlawJwzo0PT6N38PpznXMfOedmOOe+5WcMIiJyaL4NBHPO/Rhv+rk9B61P4bM67HvwJr1+xcy2+hHHxm27+ds7K9lTWe3H4eNWWloy+/bVkpIc5JwJfemSlx7rkEQkzvg5EngV8BXg6YPWDwFWmlkpgHNuGnAC3ixKTcrPz2jRYIgZS7fx9kfrj/h9HUn/XnlcMKhrrMOIisLC7FiHEHVqc2Lwo82+JQAz+5dzrt8hNuUAZY2WK4Dcwx2vpcOgJwzpyhdGnk5Jye7D79yBdC7IZOa8TTz67yVUVOyjpKQi1iH5rrAwOyHa2ZjanBha0+bmEkcsagGVA40jygZ2+XnCgtx0QtW1fp4i7hTmZ5CdmfK59bV1IZKTdO9fRGKTAJYCg5xznfEm+z4Rb+o78cmUWet5e84GKqvqqK0Lcca43lz8xUGxDktEYixqCcA5dymQZWaPOOduwJvcOwg8YWabohVHIulRkEmX3DRq6kKkpybTOSeNtVsrWP9pYnWHicih+ZoAzGwtcFz49d8arX8FeMXPcwt0zknjnu8e37AcCtVzzT3vHXLf6po6KiprqNhbTUVlDeV7qg9Yzs5I4YKTigkEmqwsKyLtTLuZD0Dazubte3jw+YWU7a6ibE81FXtrqKquO+z7Jo3uSZdcPU4q0lEoASSSAGSlp1C2p5pPlpeQFAyQk5lKt7x0sjNSyM5MJTs91XudkUJ2hvd6yqz1zF2xnfp6CNXXs3uvd4VQtqea8t3h/+6ppmxPlXflsLeG08b25gvDi2LdYhFphhJAAgkGAtx59TgqKmvIy0olMz2FYARdOh/M3wzAzX+ZQTAQIFR/+MnZPrYSJQCROKcEkGDysjqRl9XpiN5T3COXOVZCVloK+dmdyMlMJTf8b//rnKxUcjNSSUlJ4kd/nMb8ldsJ1ddHlGBEJDaUAOSwTh7dk5NH94xo3+oa715CPbB8/S6O6pvvY2Qi0hoaESRtKjUlieEDCgDYtbuKDdt2s2pTWUTdRiISXboCkDZ3dL98Fq7ewSOvLGlYd8PFIxnWvyCGUYnIwZQApM0d1Sef/kU5ZKYls7e6llWbyikp3cuatHK65aeTkfb5EhUiEn1KANLm+nbP5qffHAvA+3M3sWpTOU+/uRyAUQO78IMLRsQyPBEJ0z0A8ZXrk8fAXrmMLC4gEIDS3VWxDklEwpQAxFdFBZnc9vUx/PDCkdTXw7qtFSzf4GvxVxGJkBKARE2X3DQAtu5s2dwOItK2lAAkas4/YUCsQxCRRnQTWGKiLhRi645K1n+6mw3bdlPcM5cxrjDWYYkkFCUAibqXpq3hmbeWU1MbaljXNS9dCUAkytQFJFHTOcerQVS+p5qizhlMHFHEZacNJis9hZ0VVfz8idkNhedExH+6ApCocX3y+d3/m0hmWvIB8xLPWLyV1ZvL2bBtN3OWbcP1zqMwL51gUIXkRPykKwCJqtzM1M9NSv9fF4/ijiuPBWDRmp3c+shM3purWUJF/KYEIDGX3imZXl2zGFFcQNd8b8axXRowJuI7JQCJC8FAgOsvHMk1Xzo61qGIJAwlAIlLb8zewPpPK2IdhkiHpgQgcSUl2fuTrK0L8a//rKZe8wiI+EYJQOJKn25ZfOMMB8DSdaV8977/MG3BlhhHJdIxKQFIXAkEApw0qgcFOZ2orQtRXRtSV5CIT5QAJO4EAgF+9e3juO3rY2IdikiHpoFgEpdSkpNITWn6+0lNbR0rN5WzdF0pqzaVcdKoHnypMDuKEYq0f0oA0i7U1oVYu7WCpetKWbaulBUby6it+6yWUKeUJL504sAYRijS/igBSNz7aNk2pi7cQlV1XcO63l2zGNLXm3v44ZcXN6zftmsv23ft5ag++SolIXIYSgAStzLTUggAZXuq6dY5g6P75jOkbz6uTx7ZGakA7K2qBWD15jKuvusttoUnm/nRRSMZPqAgVqGLtAtKABK3CnLT+PmVx5LRKZkueemH3Cc5KUBqcpDyyhpC9VBUkMGWHZU8+soS/vDDE6IcsUj7ogQgca1Pt+Zv7KYkJ/GTb4ylNhTimKE9mDV/I7/+6yfs3lsTpQhF2i8lAGn3enXNAiApGGBQrzz6ds9my449VFRWs3RdKZnpKQzt1znGUYrEH98SgHMuCDwEjASqgGvMbGWj7TcDlwDlwD1m9m+/YpHEEgCqa0Jc/4dp1OOVl7jmnKNZvGYHmekpXHiynhYSAX8Hgk0G0sxsAnALcN/+Dc654cClwHHA6cCdzrkMH2ORBFJUkEFSMMDg3nnkZaVSUxvizy8u4oP5W3h95nq27dob6xBF4oKfXUATgSkAZjbTOTe20bYhwPtmtg/AObcCGAHMbOpg+fkZJCcntTiYwgQcJJSobb71yvHU1oVISU7izVnrmDp3E8OKC5g2fzNrt5TzzFsruO3KcWSlpzS8r3JfDQtWbucT28a+qlp+ePFokpLax0D5RP09Jxo/2uxnAsgByhot1znnks2sFlgI3OqcywZSgeOBR5o7WGlpZYsDKSzMpqQkserJqM2e0QM6M3qA1//fPS+Ne5+dx8JV27n9oWlceupgFq/ZwaI1O1m1qZxQo8qjc20bNbUhvnpyMSeP6hnVdhwJ/Z4TQ2va3Fzi8PMrTjnQ+MzB8Ic/ZrYUeBB4Ha9raBaw3cdYRDiqTz5jXSEAqzeX88un5vDC1DWs3FRGv6JsvvyFfrjeeQDs2l3Nnn21rNlcHsuQRXzl5xXAh8C5wHPOuePwvvUD4JwrBLqY2UTnXC7wJrDIx1hECAYDXHf+cB5/dQm2fhdH98tnaP8ChvTNb+gO2rOvhhUbyshIS+buZz5h6oItHHtUV4ZpUJl0QH4mgBeA05xz0/EezLjSOXcDsBJ4BRjgnPsIqAZuMrO6pg8l0naubmbaycy0FEYN6kJpxWdzEv/j/VVKANIh+ZYAzCwEXHvQ6mWNXn/Hr3OLtFZ+dieumzyMh15cxO69Nbw/bxO7Kqo45/h+JLeTm8Mih6OBYCJNGHtUV7LSUyitqOKpKQZAWmoyZ47vE+PIRNqGvsqINOPk0T0YUVxAl9w0AJ57byXVNeqtlI5BVwAizfjKicWAN07g+w9MBeCV6Wv56knFsQxLpE3oCkAkAhlpKQ1dP6/OWMdbH21g6dqdgFeSetm60obS1Aerr69n0/Y9vDF7Pc+8tfyAeQ1EYklXACIROv+E/kyZtR6Av7+zAoCj+uSxYmMZdaF6zpvYn/Mm9gegcl8tS9ftZOHqnSxas4Od5Z89VbSzfB/XnjeMst1VFOSmEQho4hqJDSUAkQilJCdx/YUjmTp/Mx8vLwFg2fpddM1PZ1vpXpas3UlSMMCi1TtY2WhkcWZaMuOGdKWyqpZFq3cyd8V2vnPv+wCcPKoH5584oGGCG5FoUgIQOQIjigsYUVzAuq0VbN6+h6P75VO2p5o7nvyIFRvLWLGxjAAwoEcOwwYUMGxAZ/p3zyEYDBCqr+e2h2ceUIzu/XmbeX/eZob0zecbZzq65asmokSPEoBIC/Ttnk3f7l6lk4y0FEYWF5CRlsKI4gKG9u98QKG5/YKBAHdePY69VbUEggH+57VlzFvpVUDZP9m9EoBEkxKASCulJAf54YUjI9o3NSWJ1BSvqu0PLhjBglU7WLa+lCmz1vO3t1dQ3COXjdt3M3pgIZ1SW179ViQSSgAiMTSiuIDsjBSmzFpPTW2Inz0xu2HbTV8bRUaadyWx/2pDpC0pAYjEWP+iHL40oS9TF2whGPAqkQL89tl5Dfv89Jtj6V+UE6sQpYNSAhCJA189qZivnlRMfX0981ft4A//XEBmWjJ79nljC16cuoYfXRRZN5NIpJQAROJIIBBg1MAuPHbzJAA+3VnJ7Y/OYuHqHVTV1NEpRfcFpO0oAYjEoWB4cFhhXnrDuu/e9x++eExPigoyOXFkkaqSSqspAYjEseSkIJedNphn3loOwLufbALgmbeWk52RwiO3nhrL8KSd01cIkTh3yphePHj9iUwY2o2igs/GCVRU1vD3N40qVSeVFtIVgEg7kJGWzLfOHUp9fT07yvYxZfZ63v1kEy9PXU23vDQmDO0e6xClHdIVgEg7EggE6JKXziljepGf3QmAR19ZwtNvGjvL98U4OmlvlABE2qGigky+8+WhDcvvfbKJGx+azrPhKqUikVAXkEg7Nbh3Hk/fcSaPvjCfD+ZvAeDNjzbQvXMGi9fuZN6K7Ywe1IXvTh6mktNySLoCEGnH8rI7ccVZQ7jn2gnkZnklpZ96w/jYSqgL1TPHSnj+g9XUh0tTizSmBCDSAXTJS+eSUwYxfEABF04q5r+vGU+/cP2gV2es48aHpn9uJjIlBVEXkEgHMW5IN8YN6dawfOvXx3DLwzMoraiitKKKe5+dy6rN5fTtnk16ahLL1u+iW346V549hEG9ctVNlIB0BSDSQaUkB7nve1/glGN6AbBqczkA67ZWsGz9LgA+Ld3L3c98wk8em0UoVE9tXShm8Ur06QpApIM7e0JfinvmMLBXLnOWlZCRlszwAQUsWLWd/51iAGzZUclPH5/F1h2VfHfyMMYe1TXGUUs0KAGIdHD52Z04LjxQ7MzxfRrWnzSqJyeN6smjryxmxuJP2bKjEoDH/r2E7IwUcjJTycvqxLJ1peRkplLcMzcm8Yt/lABEEtzFpwxi4ogepCYHuevpj6muDfGbv80FICkYoC7k3Sw+Y1xvvnhML5KCAZauK6VXYZYmqmnnlABEElxORio5fb1HSM8c34c5y7axvcwbVdy7axZrt1YA8MbsDbwxe0PD+4oKMjhzfB+G9M2nS2765w8scU8JQEQaXDRpIBdNGkhtXYh91XVkpacQCtXzt7eXN1QiHTagM7Z+F1t2VPLka8uYOLyIq740JMaRS0soAYjI5yQnBclK9x4SDAYDfP10xyWnDiIUqiclOYlXpq9l5cYyFq7eQXWtqpG2V3oMVEQikhQMkpLszUh27vH9uOrso2IckbSWEoCItMrspdsor6yOdRjSAr51ATnngsBDwEigCrjGzFY22n4jcAkQAn5lZi/4FYuItL3M9JSG18+8uZyLvziQzjlpMYxIjpSfVwCTgTQzmwDcAty3f4NzLg/4ATABOB14wMc4RMQHyUlBLj/DAfDRsm3c+shMzUnQzkR0BeCc6wt8H+gMNBQMMbOrmnnbRGBKeL+ZzrmxjbbtAdYBmeF/Gn8u0g5NHF7E3OUlLFqzk5raEDc+NJ07rjyWPt00PqA9iLQL6DlgavhfpCUEc4CyRst1zrlkM6sNL28AlgBJwK8Pd7D8/AySwzegWqKwMPH+INXmxBDrNv/6+yfwxsx1PPiPeQDc8eRHXHXuUMYP7U5Rl0xfiszFus2x4EebI00AKWZ24xEeuxxoHHGw0Yf/WUAR0D+8/IZz7kMzm93UwUpLK4/w9J8pLMympKSixe9vj9TmxBAvbT6muDM3Xzq6YQTxE68s5olXFnPTJaMZ0jefXburCAYC5GSmtvpc8dLmaGpNm5tLHJEmgGnOuXOBN8ws0tv9HwLnAs85544DFjbaVgrsBarMrN45twvIi/C4IhKHXJ98bvv6GF6atprFa0sBeH3WOp57dyXrPvU+vE4/tjcnjuxBjy6ZsQxVwgKRTArhnNsMdD9odb2ZNdkn0+gpoBF49w2uBM4GVprZy865XwBn4vX/TwN+bGZNBlNSUtHi2Sv0jSExqM3xY9qCLTzx2lLgwHpC+93+jTEU92hZcbl4bbOfWnkF0GQfXERXAGbW40hPamYh4NqDVi9rtP3nwM+P9LgiEv+OGdyFneX96VmYydH9OpOSHOSvby7ng/mbAVi+YVeLE4C0nUifAsrA+7A+Jfyed4GfmtkeH2MTkXYqIy2FL0/sf8C6K846ipHFBfzx+YX8471VLF6zk+smDycjTRVpYiXScQAP4j2ueRXwTSAV+ItfQYlIxzSw12ff+pesLWXN1vIYRiORpt4xZjay0fL3nXNL/AhIRDqu7IxU/vSjE3nitaV8bCW8NHUNPQoyyc/uFOvQElKkVwDB8OhdoGEkb20z+4uIHFJ6p2QG9MgBYOWmMmYs3hrjiBJXpAngfuAj59x9zrn7gY9Q+QYRaaEvDC9i1MAuAPzz/VWEIngaUdpeRAnAzJ4EzgdWA2uAr5jZE34GJiIdV05GKpeeOqhh+dp7/8OnO1s+2FNaptkE4Jw7J/zfbwDHABV45R1Gh9eJiLRIl7x0zj6uLwC1dSFufWQmV939LnOWbWPjtt2s3FhGdY0mm/HT4W4CHwv8G5h0iG31wFNtHpGIJIyvnjSA4p45/PFfnxUKeOjFRQfsc9PXRjGkX+doh5YQIhoJ3JhzLhfoZWaL/Qnp0DQS+MiozYmhI7V5+qIt/Hv6OrYeoiuo8cjhjtTmSMV0JLBz7mrgBOAmYC5Q4Zx72sx+1aKIREQOcvywIo4fVtSwPHdFScOVwUtT1zD2qK4U5Kaxcc5G6utCnH5sb4LBtq80mkgiHQdwHXAO3gxeLwE/BGYCSgAi4ovhAwq48ORi/vH+Khat2cmiNTsP2P7ce94EgxdNGkj5nmrOP7F/w5zFEpmIZwQzsy14xdxeDZd1TvctKhFJeMlJQU4f15uxR3Xl6H75gDcBTb+inAP2e+69lUyZvZ7v3PsfnntvJZu3q0JNpCK9AljsnPs3MAB42zn3f3hjAUREfJMUDHLd5GEHrCsszGbL1jJWbCzj1RlryclIZeaSTwGYMms9tXUhLj11cAyibX8iTQBXAccDi8ys2jn3V+A1/8ISEWlaclKQIX3zGdLXuzIo7pnLuq0VTFu4hbfnbOSSUwb5MhNZR3O4cQDfDr+8DTgZrwbQz4DRwO3+hiYiEplTxvRi8gmfVR/dvEODyiJxuHsAgUb/PdQ/EZG40DknjYE9vUdFQyGVlohEswnAzB4Ov7wLmGtmvwD+hDeh+50+xyYickT6dvfmv13/aQVrtpSzeO1OtrViPvGOLtJ7AI8AScDL4eVJwDg+P+OXiEjMPf7q0obXxT1zuP3ysVRUVpOakkSnFD0qul+kCeBYMxsOYGbbgcudcwv8C0tE5Mgd1SePRat38GnpXvKzO1FaUcWqTeVcdfe7gDchzW1fHxPjKONHpAkg6JwrCo8FwDnXFW8ydxGRuDHGdWWM69qw/NPHZrGp0biAlRvLWLu1nH7dcw719oQTaQK4C5jrnJsWXh6PNxpYRCRu3Xn1ODZs201Bbho//vMM9lbV8ugrS8jOSOW7k4eRm5ka6xBjKtL5AP6GVw7673gVQMeZ2fN+BiYi0lqBQIA+3bLJTEvhRxd5s9pu2VHJ8g27mL3k04R/WiiiBOCcSwWuAM4D/gN8K7xORKRdKO6Rw7XnDeXEkT0A+Ps7K/jLS4sO866OLdJaQH8CsvCuAmqAgYBmBBORdiMQCDBuSDdOHt2jYd0cK+Gqu9/lTy8sZOO23TGMLjYiTQBjzOw2oMbMKoFvAqP8C0tExB/9uufw+M2TSEv97HHQj62ED+ZvjmFUsRFpAqgPd/ns7zDr0ui1iEi7EggEuO97X+C/Lh7FKWN6ATBv5fYYRxV9kSaAB4C3ge7OuQeAOcDvfItKRMRn6Z2SGdq/M6eGE8D2sn0JN2o40gTwOt6o37uA1cC5ZqZ7ACLS7nXrnEFmmvdE/C0Pz2RTSeLcC4h0HMBUMxsCLPEzGBGRWDj7uL784/1VAKzYVEbPwqwYRxQdkSaA+c65bwCzgL37V5rZel+iEhGJotPH9aYuVM/zH6zmqSnGhwu2cNWXhlBUkBnr0HwVaQIYj1f8rXEJ6Hq8GcJERNq1pGCQwb3zGpZXbS7n9kdnce91x9M5Jy2Gkfmr2QTgnOsB3AtUANOBW8xsVzQCExGJpkG9crn168ewYmMZ/wx3B9340HRuueyYA5JDR3K4K4AngYXAM8AFwP1400MelnMuCDwEjASqgGvMbGV42yi8J4v2Ow6YbGZTjih6EZE2EggEGNQrj0G98nC987jr6Y8BuPuZT7jz6nH06oD3BQ6XAHqa2RkAzrk3gXlHcOzJQJqZTXDOHQfch1dKAjObhzfFJM65C4HN+vAXkXhR3DOXB68/ge8/MBWAnz0+m9TkIMU9c8nNSuWac44m2AHmHD7cY6DV+1+YWU3j5QhMBKaE3zsTGHvwDs65TOAXwA+O4LgiIr7LSEvh7msnNCxX14ZYuq6UmYs/5T9zN8UwsrYT6U3g/Y5k9G8OUNZouc45l2xmtY3WXQ38IzzJTLPy8zNITm75TD6Fhdktfm97pTYnBrXZ3/M8fOspLF+/C+rrmTZ/M7MWb6WyJhT1n7sf5ztcAhjqnFvdaLlneDkA1JtZc08BlQONIw4e9OEPcBnevYXDKm3FCL3CwmxKSipa/P72SG1ODGqz/1KAob29yebTkgJeAthbHdUYWtPm5hLH4RLA4Bad0fMhcC7wXPgewMLGG51zuUAnM9vQinOIiETd6zPXM3lif1Ja0SsRD5pNAGa2rhXHfgE4zTk3He+K4Urn3A3ASjN7GS+5rG3F8UVEoqprfnrD68dfXcp5E/uzZ18tA3vmxjCqlgvU17ePop4lJRUtDlSXyYlBbU4MsW7zm7PX8+y7Kw9Yd8+1E+iSl97EO1qvlV1ATT6uFGkxOBERAU4f14cxrhCAnPCcwpVVB9/ebB+O9CkgEZGE973zhwPwt7eW8/bHG2McTcvpCkBEJEEpAYiItNJf31we6xBaRAlARKSFhhcXAFBVUxfjSFpGCUBEpIWGD/ASwIZtu9myY0+MozlySgAiIm3ANrS/SvlKACIirfCtc4+OdQgtpgQgItIK+0dZPTXFaC8Da/dTAhARaYXeXT+bKKZ9ffwrAYiItErPwqyGKSNLy6tiHM2RUQIQEWmluroQADf9eTqV+2piHE3klABERFrp8jNcw+sVG8ua2TO+KAGIiLRSn27ZnHN8XwCefH1ZjKOJnBKAiEgbmDC0OwCdUtrPx2r7iVREJI4VFWSSnZFCclL7+VhtP5GKiEibUgIQEUlQSgAiIm1kb1UdW3ZUsrN8X6xDiYgSgIhIG6kNjwe48aHp7aIshBKAiEgbufnS0Q2vr/7Ne3E/KEwJQESkjbg++Uye2L9hec2WihhGc3hKACIibejLE/sfkATimRKAiEgbCwQDh98pDigBiIgkKCUAEZEEpQQgIpKglAC5WBQUAAAKfklEQVRERHxy3//NY9Xm+C0PrQQgItLGBvbIaXi9eM3OGEbSPCUAEZE2NqRfZ2782qhYh3FYSgAiIglKCUBEJEEpAYiI+OjFqWvYvTc+awIl+3Vg51wQeAgYCVQB15jZykbbzwJ+Hl78BPiemcV/+TwRkQhkZ6Q2vP7B76cCcP6JAzj3+H4xiujz/LwCmAykmdkE4Bbgvv0bnHPZwG+Bc8zsOGAt0MXHWEREoqp31ywuO23wAete+GB1XM0VEPCrZrVz7n5gtpk9G17eZGY9w6/PAK4AqoEBwGNm9r/NHa+2tq4+OTnJl1hFRPy0o2wvV9z5JgAP33oKPbpkRfP0TRYm8q0LCMgBGo+AqHPOJZtZLd63/UnAKGA3MNU5N8PMljd1sNLSyhYHUliYTUlJfJdlbWtqc2JQm9uPiSOKmLZgC9/59TtcfvpgJh3TK+L3tqbNhYXZTW7zswuoHGh85mD4wx9gB/CRmW01s93AB3jJQESkQ8rL6tTw+uk3lzfMHhZLfiaAD4GzAZxzxwELG237GBjmnOvinEsGjgOW+BiLiEhMnXt8P+68elzD8pRZ62MYjcfPLqAXgNOcc9Px+qCudM7dAKw0s5edc7cCb4T3fc7MFvkYi4hITKUkB+lVmMXkif15cdoanv9gNR/M30xuZiq3XT6GQCD6cwj4lgDMLARce9DqZY22Pws869f5RUTi0YmjevDitDUAbC/bx/ayfdTUhkhNif5DLhoIJiISRXlZnbjrW+P50UUj6d3VexrolelrYxKLEoCISJQVFWQyfEABE0cUAbBrd1VM4lACEBGJkZEDvfGvgaYf1feVEoCISIxNW7iFquq6qJ9XCUBEJEay01MaXm/Ytjvq51cCEBGJkfROyZw5vk/Mzq8EICISQ0lBr///V3/9mG2tKHnTEkoAIiIxNLRf54bX9z83P6rnVgIQEYmho/rmc8NFIwHYVrqXfdW1h3lH21ECEBGJsaH9O5MVviG8cPXOqJ1XCUBEJMYCgQBH98sH4C8vLsKveVoOpgQgIhIHLj3Vmz2sHli9uTwq51QCEBGJAzmZqQ21gfZFaVCYEoCISJwYe1TXqJ5PCUBEJM58tGxbVM6jBCAiEieyM7wngaYv2hKV8ykBiIjEiYnDvfLQGWkph9mzbSgBiIjEieSkIDkZKZTvqWb33hrfz6cEICISR/aGnwCatsD/biAlABGRODL5hP4APPfeSq66+1227drr27mUAERE4siYwYUHzA+20cd5ApQARETiSNf8DB664SQu/uJA38+lBCAiEmc6pSYRCPg/T7ASgIhIglICEBGJY4+/usS3YysBiIjEof5F2YC/heGUAERE4tCgXnn07JJJpo+jgpUAREQSlBKAiEiCUgIQEYlju/fWEAr5M0WkEoCISJyqqQsB8Nbsdb4cP9mXo4qISKudcWxvlq7fxchBhRAKtfnxfUsAzrkg8BAwEqgCrjGzlY22/wH4AlARXnWemZX5FY+ISHsz6ZheTDqmF4UFmZSUVBz+DUfIzyuAyUCamU1wzh0H3Aec12j7McAZZrbdxxhERKQJgfp6f24uOOfuB2ab2bPh5U1m1jP8OghsAT4EugGPm9kTzR2vtrauPjk5yZdYRUQ6sCaLCvl5BZADNO7SqXPOJZtZLZAJ/BG4H0gC3nPOzTGzBU0drLS0ssWBFBZm+3L5FM/U5sSgNieG1rS5sDC7yW1+PgVUDjQ+czD84Q9QCfzezCrNrAJ4F+9egYiIRImfCeBD4GyA8D2AhY22DQamOeeSnHMpwETgEx9jERGRg/jZBfQCcJpzbjpeH9SVzrkbgJVm9rJz7hlgJlADPGVmi32MRUREDuJbAjCzEHDtQauXNdp+D3CPX+cXEZHmaSSwiEiC8u0xUBERiW+6AhARSVBKACIiCUoJQEQkQSkBiIgkKCUAEZEEpQQgIpKglABERBJUh5oRLIJJaL4FfAeoBX5pZv+OSaBtKII2/wj4WnjxNTP7RfSjbDuHa2+jfV4FXjKzv0Q/yrYVwe/4LODn4cVPgO+ZWbse4BNBm28ELgFCwK/M7IWYBOoD59x44DdmdvJB688Ffob3+fWEmT3a2nN1tCuAhklogFvwJqEBwDnXHfgB3ixkZwC/ds51ikmUbau5Ng8ALgOOByYApzvnRsQkyrbTZHsb+SXQOapR+au533E28FvgHDM7DlgLdIlFkG2suTbn4f2/PAE4HXggJhH6wDn3Y+AxIO2g9SnA7/DaexLw7fBnWqt0tAQwEZgCYGYzgbGNto0DPjSzqvDUkyuB9v5hCM23eQNwppnVhWszpQD7oh9im2quvTjnLsD7Vvh69EPzTXNtPh6v0u59zrmpwKdmVhL9ENtcc23eA6zDm1ckE+/33VGsAr5yiPVD8ApplppZNTANOKG1J+toCeCQk9A0sa0CyI1WYD5qss1mVmNm251zAefcvcBcM1sekyjbTpPtdc4NAy7Fu0zuSJr7u+4CTAJuBs4CrnfODY5yfH5ors3gfblZgtfl9YdoBuYnM/sXXoXkg/ny+dXREkBzk9AcvC0b2BWtwHzUXJtxzqUBz4T3uS7KsfmhufZ+A+iJN8HQFcANzrkzoxueL5pr8w7gIzPbama7gQ+AUdEO0AfNtfksoAjoD/QBJjvnxkU5vmjz5fOroyWA5iahmQ2c4JxLc87l4l1SLYp+iG2uyTY75wLAS8B8M/uOmdXFJsQ21WR7zezHZjY+fPPsf4D7zWxKLIJsY839XX8MDHPOdQl/Qz4O75txe9dcm0uBvUCVme3D+yDMi3qE0bUUGOSc6+ycSwVOBGa09qAd6ikgDj8JzR+AqXiJ7/bwH09712Sb8eZbPgnoFH5SBOBWM2v1H04MNfs7jm1ovjnc3/WtwBvhfZ8zs47wxeZwbT4VmOmcC+H1h78Vw1h945y7FMgys0fC7X8D7/PrCTPb1Nrjqxy0iEiC6mhdQCIiEiElABGRBKUEICKSoJQAREQSlBKAiEiC6miPgYq0mHOuH7Ccz56jD+KNwPxfM/t5U+87wnPcAWBmdzjn6s0s0BbHFWkJJQCRA202s4aRtM65HsAK59yzZrY0hnGJtDklAJHmFeENRKpwzt0CXIQ3wO4N4GYzqw+X3L4WqANeMbObw3WJ/ghkAV2BX3eE0tTSsSgBiByoh3NuHl453i7AR8D5wDBgDHAsUA88DVzmnDO8Gktj8apUTnHOjQEux5tz4p1wWe75gBKAxBUlAJEDbTazUeEJSe4DjsYrM3APMB6v9g5AOrAe6I73rX9/pcZTAcJJ5MxwmYbheFcCInFFTwGJHEJ4/oSb8KqL3ojX7fOAmY0K3yMYD9yFV7q3oZ6Kc65HeMKS5/CuHJYAt0c5fJGIKAGINCFcfvhG4Kd4decvd85lhatuvghcgFdc8OxG6/+O1x10GvAzM3sJr3wxzrmkGDRDpElKACLNCJeTnoFXfvdfwCy8MuLz8B4P/QR4MLzPfOADM3sbuAOY5pxbgjdz01q8+vUicUPVQEVEEpSuAEREEpQSgIhIglICEBFJUEoAIiIJSglARCRBKQGIiCQoJQARkQT1/wFNVcKIVdjwYQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precisions, recalls, thresholds = metrics.precision_recall_curve(y, p_pred)\n",
    "\n",
    "plt.plot(recalls, precisions)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision v. Recall');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can summarize this curve in a single number: the area under the curve. If our model were perfect, precision and recall would both be 1 regardless of threshold, so the area under the curve would be 1. If our model was always wrong, the precision and recall would both be 0 regardless of threshold, so the area under the curve would be 0. The better our model is, _regardless of threshold_, the closer the area under the curve is to 1. We eventually need to a choose a threshold and may choose to prioritize precision or recall, but the **area under the precision-recall curve** (AUC), is a very useful metric for assessing model performance in classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright &copy; 2019 The Data Incubator.  All rights reserved.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nbclean": true
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
