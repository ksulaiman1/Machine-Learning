{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a05b3a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6dbde89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4d08c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28859863",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"on thursday morning, sulaiman didn't feel good\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd06d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0901b9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "115e0995",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"we can divide our sentence into words called tokens!\")\n",
    "# for sent in doc.sents:\n",
    "#     print (sent)\n",
    "#     sentences = []\n",
    "#     sentences+=[doc.sents]\n",
    "#     print (sentences) ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e74b1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "we"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ffc24b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list()\n",
    "lemma = list()\n",
    "pos = list()\n",
    "tag = list()\n",
    "explain_tag = list()\n",
    "for token in doc:\n",
    "    text.append(token.text)\n",
    "    lemma.append(token.lemma_)\n",
    "    pos.append(token.pos_)\n",
    "    tag.append(token.tag_)\n",
    "    #explain_tag.append(spacy.explain)\n",
    "    \n",
    "for tag in tag:\n",
    "    explain_tag.append(spacy.explain(tag))\n",
    "df = pd.DataFrame({'lemma': lemma, 'POS': pos, 'TAG': tag, 'TAG_EXPLANATION': explain_tag}, index=text )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9bfec85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>TAG</th>\n",
       "      <th>TAG_EXPLANATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>we</th>\n",
       "      <td>we</td>\n",
       "      <td>PRON</td>\n",
       "      <td>.</td>\n",
       "      <td>pronoun, personal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>can</th>\n",
       "      <td>can</td>\n",
       "      <td>AUX</td>\n",
       "      <td>.</td>\n",
       "      <td>verb, modal auxiliary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>divide</th>\n",
       "      <td>divide</td>\n",
       "      <td>VERB</td>\n",
       "      <td>.</td>\n",
       "      <td>verb, base form</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>our</th>\n",
       "      <td>our</td>\n",
       "      <td>PRON</td>\n",
       "      <td>.</td>\n",
       "      <td>pronoun, possessive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence</th>\n",
       "      <td>sentence</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>.</td>\n",
       "      <td>noun, singular or mass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>into</th>\n",
       "      <td>into</td>\n",
       "      <td>ADP</td>\n",
       "      <td>.</td>\n",
       "      <td>conjunction, subordinating or preposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>word</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>.</td>\n",
       "      <td>noun, plural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>called</th>\n",
       "      <td>call</td>\n",
       "      <td>VERB</td>\n",
       "      <td>.</td>\n",
       "      <td>verb, past participle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>token</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>.</td>\n",
       "      <td>noun, plural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>punctuation mark, sentence closer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             lemma    POS TAG                            TAG_EXPLANATION\n",
       "we              we   PRON   .                          pronoun, personal\n",
       "can            can    AUX   .                      verb, modal auxiliary\n",
       "divide      divide   VERB   .                            verb, base form\n",
       "our            our   PRON   .                        pronoun, possessive\n",
       "sentence  sentence   NOUN   .                     noun, singular or mass\n",
       "into          into    ADP   .  conjunction, subordinating or preposition\n",
       "words         word   NOUN   .                               noun, plural\n",
       "called        call   VERB   .                      verb, past participle\n",
       "tokens       token   NOUN   .                               noun, plural\n",
       "!                !  PUNCT   .          punctuation mark, sentence closer"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f8c81c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer, NORM, ORTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efba3d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "phoneRegex2 = re.compile(r'(\\+?[0-9]{1,3}[\\s\\-]?[0-9]{2,3}[\\s\\-]?[0-9]{3}[\\s\\-]?[0-9]{3}|[0-9]{4}[\\s\\-]?[0-9]{3}[\\s\\-]?[0-9]{3})')\n",
    "\n",
    "dateRegex = re.compile(r'(\\d{1,2}\\s\\w{3}\\.?\\s\\d{4}|\\d{1,2}[\\/\\-]+\\d{1,2}[\\/\\-]+\\d{2,4}|\\d{1,2}\\w{2}\\s\\w{3}\\.?\\s\\d{4})')\n",
    "\n",
    "timeRegex = re.compile(r'\\d{1,2}:\\d{2}')\n",
    "\n",
    "dollarRegex = re.compile(r'\\$\\d(?:\\d+(?:[.,]?\\d*)*)+|\\€\\d(?:\\d+(?:[.,]?\\d*)*)+|\\£\\d(?:\\d+(?:[.,]?\\d*)*)+')\n",
    "\n",
    "currencyRegex = re.compile(r'(?:[A-Z]{3}\\s)(?:\\d+(?:[.,]?\\d*)*)')\n",
    "\n",
    "shillingRegex = re.compile(r'(?:\\d+(?:[.,]?\\d*)*)\\/-|(?:\\d+(?:[.,]?\\d*)*)\\/=')\n",
    "\n",
    "percentageRegex = re.compile(r'\\d+%|\\d+.\\d+%')\n",
    "\n",
    "rangeRegex = re.compile(r'\\d+-\\d+(?:[\\s.,])?\\d*')\n",
    "\n",
    "nounClassRegex = re.compile(r'([a-zA-Z]+)\\s(\\d{2,}\\.\\d{2,}|\\d{2,}\\.\\d|\\d\\.\\d{2,}|\\d\\.\\d|\\d{2,}|\\d)')\n",
    "\n",
    "numberRegex = re.compile(r'\\d+')\n",
    "\n",
    "measurementRegex = re.compile(r'(\\d+\\.\\d+|\\d+)(\\s)?(\\'|ft|miles|cc|inch|[kKHDdcm]?[mglL])')\n",
    "\n",
    "abbRegex = re.compile(r'\\b(?:[a-z]*[A-Z][a-z]*){2,}')\n",
    "\n",
    "numberplateRegex = re.compile(r'([A-Z]{2,3}\\s?\\d+[A-Z]{1})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1425f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(nlp):\n",
    "    return Tokenizer(nlp.vocab, rules=special_cases,\n",
    "                                prefix_search=prefix_re.search,\n",
    "                                suffix_search=suffix_re.search,\n",
    "                                infix_finditer=infix_re.finditer,\n",
    "                                url_match=simple_url_re.match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f4a3bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "223c29a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50686bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'i']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sw for sw in stop_words if len(sw)==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a519c65d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
